{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc3e6677-956d-4f7f-a7a6-1d6d44666b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from a_api import TextMetrics, load_ngrams\n",
    "from plot import plot_dict, plot_dict_bars, matrix_plot\n",
    "from util import dictcount\n",
    "\n",
    "grand_t0 = dt.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee9b94c-65a5-455a-b64e-4c94f9aa96f2",
   "metadata": {},
   "source": [
    "# Create Datasets\n",
    "## Merge original binary and multiclass datasets into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70e23ec1-9a14-44c4-86bb-85b8836c43f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset: Unclassified distortions (halilbabacan)\n",
    "# Paper: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4582307\n",
    "# Data: https://huggingface.co/datasets/halilbabacan/autotrain-data-cognitive_distortions\n",
    "# https://huggingface.co/datasets/halilbabacan/autotrain-data-cognitive_distortions/tree/main/raw\n",
    "# https://huggingface.co/datasets/halilbabacan/autotrain-data-cognitive_distortions/blob/main/raw/Cognitive_distortions.csv\n",
    "    \n",
    "binary_dataset_file_path = \"../../data/corpora/English/distortions/halilbabacan/raw_Cognitive_distortions.csv\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98db1151-56ee-469a-8834-aa5d7d44b095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.10).\n",
      "Path to dataset files: C:\\Users\\anton\\.cache\\kagglehub\\datasets\\sagarikashreevastava\\cognitive-distortion-detetction-dataset\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "# Dataset: Multiple Distorions (sagarikashreevastava)\n",
    "# Paper: https://aclanthology.org/2021.clpsych-1.17/\n",
    "# Data: https://www.kaggle.com/datasets/sagarikashreevastava/cognitive-distortion-detetction-dataset\n",
    "\n",
    "# !pip install kagglehub\n",
    "import kagglehub\n",
    "multiclass_dataset_path = kagglehub.dataset_download(\"sagarikashreevastava/cognitive-distortion-detetction-dataset\")\n",
    "print(\"Path to dataset files:\", multiclass_dataset_path)\n",
    "multiclass_dataset_file_path = multiclass_dataset_path + \"/Annotated_data.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c877567-5aaa-4dde-8f02-e98dd6df749e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient Question</th>\n",
       "      <th>Distorted part</th>\n",
       "      <th>Dominant Distortion</th>\n",
       "      <th>Secondary Distortion (Optional)l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm such a failure I never do anything right.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Distortion</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nobody likes me because I'm not interesting.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Distortion</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I can't try new things because I'll just mess...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Distortion</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My boss didn't say 'good morning' she must be...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Distortion</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My friend didn't invite me to the party I mus...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Distortion</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3522</th>\n",
       "      <td>Since then whenever my mother is out alone I b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Distortion</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3523</th>\n",
       "      <td>My family hate him but they didn’t met him at ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Distortion</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3524</th>\n",
       "      <td>However I am not happy at the least only half ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Distortion</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3525</th>\n",
       "      <td>Now I am at university my peers around me all ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Distortion</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3526</th>\n",
       "      <td>He claims he’s severely depressed and has outb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Distortion</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3527 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Patient Question  Distorted part  \\\n",
       "0         I'm such a failure I never do anything right.             NaN   \n",
       "1          Nobody likes me because I'm not interesting.             NaN   \n",
       "2      I can't try new things because I'll just mess...             NaN   \n",
       "3      My boss didn't say 'good morning' she must be...             NaN   \n",
       "4      My friend didn't invite me to the party I mus...             NaN   \n",
       "...                                                 ...             ...   \n",
       "3522  Since then whenever my mother is out alone I b...             NaN   \n",
       "3523  My family hate him but they didn’t met him at ...             NaN   \n",
       "3524  However I am not happy at the least only half ...             NaN   \n",
       "3525  Now I am at university my peers around me all ...             NaN   \n",
       "3526  He claims he’s severely depressed and has outb...             NaN   \n",
       "\n",
       "     Dominant Distortion  Secondary Distortion (Optional)l  \n",
       "0             Distortion                               NaN  \n",
       "1             Distortion                               NaN  \n",
       "2             Distortion                               NaN  \n",
       "3             Distortion                               NaN  \n",
       "4             Distortion                               NaN  \n",
       "...                  ...                               ...  \n",
       "3522          Distortion                               NaN  \n",
       "3523          Distortion                               NaN  \n",
       "3524          Distortion                               NaN  \n",
       "3525          Distortion                               NaN  \n",
       "3526          Distortion                               NaN  \n",
       "\n",
       "[3527 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(binary_dataset_file_path)\n",
    "df1 = df1.rename(columns={'Text': 'Patient Question', 'Label': 'Dominant Distortion'})\n",
    "df1.insert(1, \"Distorted part\", value = np.nan)\n",
    "df1.insert(3, \"Secondary Distortion (Optional)l\", value = np.nan)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb7f7254-fd1b-4fb2-91cc-cd7bf8b77a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient Question</th>\n",
       "      <th>Distorted part</th>\n",
       "      <th>Dominant Distortion</th>\n",
       "      <th>Secondary Distortion (Optional)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello, I have a beautiful,smart,outgoing and a...</td>\n",
       "      <td>The voice are always fimilar (someone she know...</td>\n",
       "      <td>Personalization</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Since I was about 16 years old I’ve had these ...</td>\n",
       "      <td>I feel trapped inside my disgusting self and l...</td>\n",
       "      <td>Labeling</td>\n",
       "      <td>Emotional Reasoning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So I’ve been dating on and off this guy for a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Distortion</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My parents got divorced in 2004. My mother has...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Distortion</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I don’t really know how to explain the situati...</td>\n",
       "      <td>I refused to go because I didn’t know if it wa...</td>\n",
       "      <td>Fortune-telling</td>\n",
       "      <td>Emotional Reasoning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2525</th>\n",
       "      <td>I’m a 21 year old female. I spent most of my l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Distortion</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2526</th>\n",
       "      <td>I am 21 female and have not had any friends fo...</td>\n",
       "      <td>Now I am at university my peers around me all ...</td>\n",
       "      <td>Overgeneralization</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2527</th>\n",
       "      <td>From the U.S.: My brother is 19 years old and ...</td>\n",
       "      <td>He claims he’s severely depressed and has outb...</td>\n",
       "      <td>Mental filter</td>\n",
       "      <td>Mind Reading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2528</th>\n",
       "      <td>From the U.S.: I am a 21 year old woman who ha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Distortion</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2529</th>\n",
       "      <td>I recently moved out on my ex-roommate because...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Distortion</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2530 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Patient Question  \\\n",
       "0     Hello, I have a beautiful,smart,outgoing and a...   \n",
       "1     Since I was about 16 years old I’ve had these ...   \n",
       "2      So I’ve been dating on and off this guy for a...   \n",
       "3     My parents got divorced in 2004. My mother has...   \n",
       "4     I don’t really know how to explain the situati...   \n",
       "...                                                 ...   \n",
       "2525  I’m a 21 year old female. I spent most of my l...   \n",
       "2526  I am 21 female and have not had any friends fo...   \n",
       "2527  From the U.S.: My brother is 19 years old and ...   \n",
       "2528  From the U.S.: I am a 21 year old woman who ha...   \n",
       "2529  I recently moved out on my ex-roommate because...   \n",
       "\n",
       "                                         Distorted part Dominant Distortion  \\\n",
       "0     The voice are always fimilar (someone she know...     Personalization   \n",
       "1     I feel trapped inside my disgusting self and l...            Labeling   \n",
       "2                                                   NaN       No Distortion   \n",
       "3                                                   NaN       No Distortion   \n",
       "4     I refused to go because I didn’t know if it wa...     Fortune-telling   \n",
       "...                                                 ...                 ...   \n",
       "2525                                                NaN       No Distortion   \n",
       "2526  Now I am at university my peers around me all ...  Overgeneralization   \n",
       "2527  He claims he’s severely depressed and has outb...       Mental filter   \n",
       "2528                                                NaN       No Distortion   \n",
       "2529                                                NaN       No Distortion   \n",
       "\n",
       "     Secondary Distortion (Optional)  \n",
       "0                                NaN  \n",
       "1                Emotional Reasoning  \n",
       "2                                NaN  \n",
       "3                                NaN  \n",
       "4                Emotional Reasoning  \n",
       "...                              ...  \n",
       "2525                             NaN  \n",
       "2526                             NaN  \n",
       "2527                    Mind Reading  \n",
       "2528                             NaN  \n",
       "2529                             NaN  \n",
       "\n",
       "[2530 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(multiclass_dataset_file_path) \n",
    "df2 = df2.drop('Id_Number', axis=1) # delete columnb with id \n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9055ae67-516a-4fc2-b5f2-d302bf22de14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient Question</th>\n",
       "      <th>Distorted part</th>\n",
       "      <th>Dominant Distortion</th>\n",
       "      <th>Secondary Distortion (Optional)l</th>\n",
       "      <th>Secondary Distortion (Optional)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm such a failure I never do anything right.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Distortion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nobody likes me because I'm not interesting.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Distortion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I can't try new things because I'll just mess...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Distortion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My boss didn't say 'good morning' she must be...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Distortion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My friend didn't invite me to the party I mus...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Distortion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6052</th>\n",
       "      <td>I’m a 21 year old female. I spent most of my l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Distortion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6053</th>\n",
       "      <td>I am 21 female and have not had any friends fo...</td>\n",
       "      <td>Now I am at university my peers around me all ...</td>\n",
       "      <td>Overgeneralization</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6054</th>\n",
       "      <td>From the U.S.: My brother is 19 years old and ...</td>\n",
       "      <td>He claims he’s severely depressed and has outb...</td>\n",
       "      <td>Mental filter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mind Reading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6055</th>\n",
       "      <td>From the U.S.: I am a 21 year old woman who ha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Distortion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6056</th>\n",
       "      <td>I recently moved out on my ex-roommate because...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Distortion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6057 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Patient Question  \\\n",
       "0         I'm such a failure I never do anything right.   \n",
       "1          Nobody likes me because I'm not interesting.   \n",
       "2      I can't try new things because I'll just mess...   \n",
       "3      My boss didn't say 'good morning' she must be...   \n",
       "4      My friend didn't invite me to the party I mus...   \n",
       "...                                                 ...   \n",
       "6052  I’m a 21 year old female. I spent most of my l...   \n",
       "6053  I am 21 female and have not had any friends fo...   \n",
       "6054  From the U.S.: My brother is 19 years old and ...   \n",
       "6055  From the U.S.: I am a 21 year old woman who ha...   \n",
       "6056  I recently moved out on my ex-roommate because...   \n",
       "\n",
       "                                         Distorted part Dominant Distortion  \\\n",
       "0                                                   NaN          Distortion   \n",
       "1                                                   NaN          Distortion   \n",
       "2                                                   NaN          Distortion   \n",
       "3                                                   NaN          Distortion   \n",
       "4                                                   NaN          Distortion   \n",
       "...                                                 ...                 ...   \n",
       "6052                                                NaN       No Distortion   \n",
       "6053  Now I am at university my peers around me all ...  Overgeneralization   \n",
       "6054  He claims he’s severely depressed and has outb...       Mental filter   \n",
       "6055                                                NaN       No Distortion   \n",
       "6056                                                NaN       No Distortion   \n",
       "\n",
       "      Secondary Distortion (Optional)l Secondary Distortion (Optional)  \n",
       "0                                  NaN                             NaN  \n",
       "1                                  NaN                             NaN  \n",
       "2                                  NaN                             NaN  \n",
       "3                                  NaN                             NaN  \n",
       "4                                  NaN                             NaN  \n",
       "...                                ...                             ...  \n",
       "6052                               NaN                             NaN  \n",
       "6053                               NaN                             NaN  \n",
       "6054                               NaN                    Mind Reading  \n",
       "6055                               NaN                             NaN  \n",
       "6056                               NaN                             NaN  \n",
       "\n",
       "[6057 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.concat([df1, df2], ignore_index=True)\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f91a52-14a6-446c-950b-cf17564d9fbb",
   "metadata": {},
   "source": [
    "## Create 3 split datasets for evaluation\n",
    "\n",
    "### Evaluate new split models individually for each of 3 parts against the models learned on the other 2 parts \n",
    "- parts\n",
    "  - part1 = df[df.index % 3 == 1] # dfs[1] - test on model from third_split\n",
    "  - part2 = df[df.index % 3 == 2] # dfs[2] - test on model from second_split\n",
    "  - part3 = df[df.index % 3 == 0] # dfs[0] - test on model from first_split\n",
    "- train-test splits\n",
    "  - (pd.concat([part1, part2]), part3),  # first_split:  (1 + 2) -> train, (3) -> test\n",
    "  - (pd.concat([part1, part3]), part2),  # second_split: (1 + 3) -> train, (2) -> test\n",
    "  - (pd.concat([part2, part3]), part1)   # third_split:  (2 + 3) -> train, (1) -> test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7396839f-e385-4d02-87de-571107a3e6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6057\n",
      "2019\n",
      "2019\n",
      "2019\n"
     ]
    }
   ],
   "source": [
    "df3s = [ df3.iloc[:0,:].copy(), df3.iloc[:0,:].copy(), df3.iloc[:0,:].copy()]\n",
    "\n",
    "row_n = 0 \n",
    "for _, row in df3.iterrows():\n",
    "    r3 = row_n % 3\n",
    "    row_n += 1\n",
    "    df = df3s[r3]\n",
    "    df.loc[len(df)] = row\n",
    "\n",
    "print(len(df3))\n",
    "for df in df3s:\n",
    "    print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d93aed53-fff9-49a8-88ed-92a310b1ee3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "part1 = df3s[1]\n",
    "part2 = df3s[2]\n",
    "part3 = df3s[0]\n",
    "splits = { # train, test\n",
    "    'first_split':(pd.concat([part1, part2]), part3),\n",
    "    'second_split':(pd.concat([part1, part3]), part2),\n",
    "    'third_split':(pd.concat([part2, part3]), part1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e7279f-e1ee-4cb8-b8a5-ea8f7c519687",
   "metadata": {},
   "source": [
    "# Create Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3327272-a62f-46d7-9ed0-65852bd5b3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_metrics(lang,metrics_list,path):\n",
    "    metrics = {}\n",
    "    for m in metrics_list:\n",
    "        metrics[m] = path + lang + '/' + m + '.txt'\n",
    "    return metrics\n",
    "\n",
    "def our_evaluator_tm_any(tm,text,threshold):\n",
    "    metrics = tm.get_sentiment_words(text)\n",
    "    for m in metrics:\n",
    "        if metrics[m] > threshold:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def our_evaluator_tm_avg(tm,text,threshold):\n",
    "    metrics = tm.get_sentiment_words(text)\n",
    "    l = list(metrics.values())\n",
    "    avg = sum(l) / len(l) if  len(l) > 0 else 0\n",
    "    if avg > threshold:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def our_evaluator_tm_true(tm,text,threshold):\n",
    "    return True\n",
    "    \n",
    "def our_evaluator_tm_false(tm,text,threshold):\n",
    "    return False\n",
    "\n",
    "def our_evaluator_tm_random(tm,text,threshold):\n",
    "    return random.choice([True, False])\n",
    "\n",
    "def f1_from_counts(true_positive, true_negative, false_positive, false_negative):\n",
    "    precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0\n",
    "    recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
    "    return 2 * precision * recall / (precision + recall) if precision > 0 or recall > 0 else 0 \n",
    "\n",
    "def evaluate_tm_df_counts(df,tm,evaluator,threshold,debug=False):\n",
    "    true_positive = 0\n",
    "    true_negative = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "    for _, row in df.iterrows():\n",
    "        # Text definition: first, check the 2nd column; if NaN, take the text from the 1st column.\n",
    "        text = row.iloc[1] if pd.notna(row.iloc[1]) else row.iloc[0]\n",
    "        primary_distortion = row.iloc[2]  # The main cognitive distortion from the 3rd column\n",
    "        secondary_distortion = row.iloc[3] if pd.notna(row.iloc[3]) else None  # The secondary distortion from the 4th column, if it exists\n",
    "        ground_distortion = False if primary_distortion == 'No Distortion' else True\n",
    "                       \n",
    "        our_distortion = evaluator(tm,text,threshold)\n",
    "        \n",
    "        # https://en.wikipedia.org/wiki/F-score\n",
    "        if ground_distortion == True and our_distortion == True:\n",
    "            true_positive += 1\n",
    "        if ground_distortion == False and our_distortion == True:\n",
    "            false_positive += 1\n",
    "        if ground_distortion == False and our_distortion == False:\n",
    "            true_negative += 1\n",
    "        if ground_distortion == True and our_distortion == False:\n",
    "            false_negative += 1\n",
    "\n",
    "        if debug:\n",
    "            print(ground_distortion,our_distortion,text[:20],metrics)\n",
    "\n",
    "    return true_positive, true_negative, false_positive, false_negative\n",
    "\n",
    "def evaluate_tm_df(df,evaluator,threshold,debug=False):\n",
    "    true_positive, true_negative, false_positive, false_negative = evaluate_df_counts(df,tm,evaluator,threshold,debug)\n",
    "    return f1_from_counts(true_positive, true_negative, false_positive, false_negative) \n",
    "\n",
    "def evaluate_tm_df_acc_f1(df,tm,evaluator,threshold,debug=False):\n",
    "    true_positive, true_negative, false_positive, false_negative = evaluate_tm_df_counts(df,tm,evaluator,threshold,debug)\n",
    "    return (true_positive + true_negative) / len(df), f1_from_counts(true_positive, true_negative, false_positive, false_negative) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3efb0cf6-64a2-42f2-895a-bfd5632088c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/models/distortions/split_combined/multiclass_view_cleaned/first_split/\n",
      "['All-or-nothing_thinking.txt', 'Distortion.txt', 'Emotional_Reasoning.txt', 'Fortune-telling.txt', 'Labeling.txt', 'Magnification.txt', 'Mental_filter.txt', 'Mind_Reading.txt', 'No_Distortion.txt', 'Overgeneralization.txt', 'Personalization.txt', 'Should_statements.txt']\n",
      "../../data/models/distortions/split_combined/multiclass_view_cleaned/second_split/\n",
      "['All-or-nothing_thinking.txt', 'Distortion.txt', 'Emotional_Reasoning.txt', 'Fortune-telling.txt', 'Labeling.txt', 'Magnification.txt', 'Mental_filter.txt', 'Mind_Reading.txt', 'No_Distortion.txt', 'Overgeneralization.txt', 'Personalization.txt', 'Should_statements.txt']\n",
      "../../data/models/distortions/split_combined/multiclass_view_cleaned/third_split/\n",
      "['All-or-nothing_thinking.txt', 'Distortion.txt', 'Emotional_Reasoning.txt', 'Fortune-telling.txt', 'Labeling.txt', 'Magnification.txt', 'Mental_filter.txt', 'Mind_Reading.txt', 'No_Distortion.txt', 'Overgeneralization.txt', 'Personalization.txt', 'Should_statements.txt']\n"
     ]
    }
   ],
   "source": [
    "root_path = '../../data/models/distortions/split_combined/multiclass_view_cleaned/'\n",
    "if not os.path.exists(root_path+'joint'):\n",
    "    os.makedirs(root_path+'joint')\n",
    "unionset_files = {}\n",
    "for split_name in ['first_split','second_split','third_split']:\n",
    "    split_path = root_path+split_name+'/'\n",
    "    print(split_path)\n",
    "    files = os.listdir(split_path)\n",
    "    print(files)\n",
    "    for file in files:\n",
    "        if not file in unionset_files:\n",
    "            unionset_files[file] = {}\n",
    "        union = unionset_files[file]\n",
    "        ngrams = load_ngrams(split_path+file,encoding=\"utf-8\")\n",
    "        for ngram in ngrams:\n",
    "            dictcount(union,ngram)\n",
    "for file in unionset_files:\n",
    "    cross = set()\n",
    "    union = unionset_files[file]\n",
    "    for ngram in union:\n",
    "        if union[ngram] >= 3:\n",
    "            cross.add(ngram)\n",
    "    with open(root_path+'joint/'+file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for ngram in cross:\n",
    "            ngram_str = ' '.join(ngram)\n",
    "            f.write(f\"{ngram_str}\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbf86449-ad74-4a3c-bae5-e2e758abb5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/models/distortions/split_combined/binary_view_cleaned/first_split/\n",
      "['Distortion.txt', 'No_Distortion.txt']\n",
      "../../data/models/distortions/split_combined/binary_view_cleaned/second_split/\n",
      "['Distortion.txt', 'No_Distortion.txt']\n",
      "../../data/models/distortions/split_combined/binary_view_cleaned/third_split/\n",
      "['Distortion.txt', 'No_Distortion.txt']\n"
     ]
    }
   ],
   "source": [
    "root_path = '../../data/models/distortions/split_combined/binary_view_cleaned/'\n",
    "if not os.path.exists(root_path+'joint'):\n",
    "    os.makedirs(root_path+'joint')\n",
    "unionset_files = {}\n",
    "for split_name in ['first_split','second_split','third_split']:\n",
    "    split_path = root_path+split_name+'/'\n",
    "    print(split_path)\n",
    "    files = os.listdir(split_path)\n",
    "    print(files)\n",
    "    for file in files:\n",
    "        if not file in unionset_files:\n",
    "            unionset_files[file] = {}\n",
    "        union = unionset_files[file]\n",
    "        ngrams = load_ngrams(split_path+file,encoding=\"utf-8\")\n",
    "        for ngram in ngrams:\n",
    "            dictcount(union,ngram)\n",
    "for file in unionset_files:\n",
    "    cross = set()\n",
    "    union = unionset_files[file]\n",
    "    for ngram in union:\n",
    "        if union[ngram] >= 3:\n",
    "            cross.add(ngram)\n",
    "    with open(root_path+'joint/'+file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for ngram in cross:\n",
    "            ngram_str = ' '.join(ngram)\n",
    "            f.write(f\"{ngram_str}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c46d9870-4941-42ef-a9ad-3303450eebb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "278314f9-158c-435b-b055-c467ab9e91c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models['Ours base (binary: distortions and emotions), log'] = TextMetrics(language_metrics('',['distortions-all-emotions'],\n",
    "                                            path='../../data/models/distortions/ours/'),metric_logarithmic=True,debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3eb0b826-62f9-424d-817f-025e6fa6c035",
   "metadata": {},
   "outputs": [],
   "source": [
    "models['Ours base (binary: distortions and negative emotions), log'] = TextMetrics(language_metrics('',['distortions-negative-emotions'],\n",
    "                                            path='../../data/models/distortions/ours/'),metric_logarithmic=True,debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90d8f6e7-968b-4bfb-8048-7f0b23575dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models['Ours base (binary: distortions only), log'] = TextMetrics(language_metrics('',['distortions-only'],\n",
    "                                            path='../../data/models/distortions/ours/'),metric_logarithmic=True,debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0290294a-5870-4f51-90f4-02cc2d90316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models['Ours base (multi-class: distortions and emotions), log'] = TextMetrics(language_metrics('',['positive','negative','rude',\n",
    "                                            'catastrophizing','dichotomous-reasoning','disqualifying-positive','emotional-reasoning',\n",
    "                                            'fortune-telling','labeling','magnification','mental-filtering','mindreading',\n",
    "                                            'overgeneralizing','personalizing','should-statement'],\n",
    "                                            path='../../data/models/distortions/ours/'),metric_logarithmic=True,debug=False)\n",
    "\n",
    "models['Ours base (multi-class: distortions and emotions), no log'] = TextMetrics(language_metrics('',['positive','negative','rude',\n",
    "                                            'catastrophizing','dichotomous-reasoning','disqualifying-positive','emotional-reasoning',\n",
    "                                            'fortune-telling','labeling','magnification','mental-filtering','mindreading',\n",
    "                                            'overgeneralizing','personalizing','should-statement'],\n",
    "                                            path='../../data/models/distortions/ours/'),metric_logarithmic=False,debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29b7e3bd-b2dd-43b1-935f-ae8a700a29d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "models['Ours new (binary), log'] = TextMetrics(language_metrics('',['Distortion'],\n",
    "                                            path='../../data/models/distortions/overfitting_combined/binary_view/'),\n",
    "                                            encoding=\"utf-8\",metric_logarithmic=True,debug=False)\n",
    "\n",
    "models['Ours new (binary), no log'] = TextMetrics(language_metrics('',['Distortion'],\n",
    "                                            path='../../data/models/distortions/overfitting_combined/binary_view/'),\n",
    "                                            encoding=\"utf-8\",metric_logarithmic=False,debug=False)\n",
    "\n",
    "models['Ours new (binary, clean), log'] = TextMetrics(language_metrics('',['Distortion'],\n",
    "                                            path='../../data/models/distortions/overfitting_combined/binary_view_cleaned/'),\n",
    "                                            encoding=\"utf-8\",metric_logarithmic=True,debug=False)\n",
    "\n",
    "models['Ours new (binary, clean), no log'] = TextMetrics(language_metrics('',['Distortion'],\n",
    "                                            path='../../data/models/distortions/overfitting_combined/binary_view_cleaned/'),\n",
    "                                            encoding=\"utf-8\",metric_logarithmic=False,debug=False)\n",
    "\n",
    "models['Ours new (binary, joint), log'] = TextMetrics(language_metrics('',['Distortion'],\n",
    "                                            path='../../data/models/distortions/split_combined/binary_view_cleaned/joint/'),\n",
    "                                            encoding=\"utf-8\",metric_logarithmic=True,debug=False)\n",
    "\n",
    "models['Ours new (binary, joint), no log'] = TextMetrics(language_metrics('',['Distortion'],\n",
    "                                            path='../../data/models/distortions/split_combined/binary_view_cleaned/joint/'),\n",
    "                                            encoding=\"utf-8\",metric_logarithmic=False,debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c010dade-43ea-441a-9fb7-4d95ae2ec10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models['Ours new (multi-class), log'] = TextMetrics(language_metrics('',['All-or-nothing_thinking','Fortune-telling','Mental_filter','Overgeneralization','Distortion',\n",
    "                                                'Labeling','Mind_Reading','Personalization','Emotional_Reasoning','Magnification',\n",
    "                                                'Should_statements'],\n",
    "                                            path='../../data/models/distortions/overfitting_combined/multiclass_view/'),\n",
    "                                            encoding=\"utf-8\",metric_logarithmic=True,debug=False)\n",
    "\n",
    "models['Ours new (multi-class), no log'] = TextMetrics(language_metrics('',['All-or-nothing_thinking','Fortune-telling','Mental_filter','Overgeneralization','Distortion',\n",
    "                                                'Labeling','Mind_Reading','Personalization','Emotional_Reasoning','Magnification',\n",
    "                                                'Should_statements'],\n",
    "                                            path='../../data/models/distortions/overfitting_combined/multiclass_view/'),\n",
    "                                            encoding=\"utf-8\",metric_logarithmic=False,debug=False)\n",
    "\n",
    "models['Ours new (multi-class, clean), log'] = TextMetrics(language_metrics('',['All-or-nothing_thinking','Fortune-telling','Mental_filter','Overgeneralization','Distortion',\n",
    "                                                'Labeling','Mind_Reading','Personalization','Emotional_Reasoning','Magnification',\n",
    "                                                'Should_statements'],\n",
    "                                            path='../../data/models/distortions/overfitting_combined/multiclass_view_cleaned/'),\n",
    "                                            encoding=\"utf-8\",metric_logarithmic=True,debug=False)\n",
    "\n",
    "models['Ours new (multi-class, clean), no log'] = TextMetrics(language_metrics('',['All-or-nothing_thinking','Fortune-telling','Mental_filter','Overgeneralization','Distortion',\n",
    "                                                'Labeling','Mind_Reading','Personalization','Emotional_Reasoning','Magnification',\n",
    "                                                'Should_statements'],\n",
    "                                            path='../../data/models/distortions/overfitting_combined/multiclass_view_cleaned/'),\n",
    "                                            encoding=\"utf-8\",metric_logarithmic=False,debug=False)\n",
    "\n",
    "models['Ours new (multi-class, joint), log'] = TextMetrics(language_metrics('',['All-or-nothing_thinking','Fortune-telling','Mental_filter','Overgeneralization','Distortion',\n",
    "                                                'Labeling','Mind_Reading','Personalization','Emotional_Reasoning','Magnification',\n",
    "                                                'Should_statements'],\n",
    "                                            path='../../data/models/distortions/split_combined/multiclass_view_cleaned/joint/'),\n",
    "                                            encoding=\"utf-8\",metric_logarithmic=True,debug=False)\n",
    "\n",
    "models['Ours new (multi-class, joint), no log'] = TextMetrics(language_metrics('',['All-or-nothing_thinking','Fortune-telling','Mental_filter','Overgeneralization','Distortion',\n",
    "                                                'Labeling','Mind_Reading','Personalization','Emotional_Reasoning','Magnification',\n",
    "                                                'Should_statements'],\n",
    "                                            path='../../data/models/distortions/split_combined/multiclass_view_cleaned/joint/'),\n",
    "                                            encoding=\"utf-8\",metric_logarithmic=False,debug=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e09b914-c41c-4ebb-bf40-9c58d1f329cb",
   "metadata": {},
   "source": [
    "# Evaluate Different Models\n",
    "## Evaluate All \"Ours\" Models without of Splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93dc6a1f-0469-46ff-a436-933eefabc0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "models_results = {}\n",
    "models_acc = []\n",
    "models_f1 = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3848a418-bcd9-4645-a561-77611f4a6951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ours base (binary: distortions and emotions), log\n",
      "Ours base (binary: distortions and emotions), log 0.1 0.686313356447086 0.8139808106520462\n",
      "Ours base (binary: distortions and emotions), log 0.2 0.686313356447086 0.8139808106520462\n",
      "Ours base (binary: distortions and emotions), log 0.3 0.686313356447086 0.8138714733542319\n",
      "Ours base (binary: distortions and emotions), log 0.4 0.6823509988443124 0.8105180224542051\n",
      "Ours base (binary: distortions and emotions), log 0.5 0.6764074624401519 0.8007320048800326\n",
      "Ours base (binary: distortions and emotions), log 0.6 0.7021627868581806 0.7865088757396449\n",
      "Ours base (binary: distortions and emotions), log 0.7 0.5804853888063398 0.5727257440726417\n",
      "Ours base (binary: distortions and emotions), log 0.8 0.3607396400858511 0.14146341463414633\n",
      "Ours base (binary: distortions and emotions), log 0.9 0.30873369654944693 0.001907032181168057\n",
      "Ours base (binary: distortions and emotions), log 0.6 0.7021627868581806 0.7865088757396449 1.683889 0.0002780070992240383\n",
      "Ours base (binary: distortions and negative emotions), log\n",
      "Ours base (binary: distortions and negative emotions), log 0.1 0.6683176490011556 0.8011875309252845\n",
      "Ours base (binary: distortions and negative emotions), log 0.2 0.6702988278025425 0.8021008819740363\n",
      "Ours base (binary: distortions and negative emotions), log 0.3 0.6722800066039294 0.8013211890701633\n",
      "Ours base (binary: distortions and negative emotions), log 0.4 0.6760772659732541 0.7962193601994184\n",
      "Ours base (binary: distortions and negative emotions), log 0.5 0.6775631500742942 0.7676935886761032\n",
      "Ours base (binary: distortions and negative emotions), log 0.6 0.6027736503219415 0.6199052132701423\n",
      "Ours base (binary: distortions and negative emotions), log 0.7 0.4089483242529305 0.2554076539101497\n",
      "Ours base (binary: distortions and negative emotions), log 0.8 0.3207858675912168 0.03608247422680412\n",
      "Ours base (binary: distortions and negative emotions), log 0.9 0.30807330361565133 0\n",
      "Ours base (binary: distortions and negative emotions), log 0.5 0.6775631500742942 0.7676935886761032 1.607723 0.0002654322271751692\n",
      "Ours base (binary: distortions only), log\n",
      "Ours base (binary: distortions only), log 0.1 0.5217104176985307 0.6525128943264963\n",
      "Ours base (binary: distortions only), log 0.2 0.564966154862143 0.6688450421012944\n",
      "Ours base (binary: distortions only), log 0.3 0.5960046227505366 0.6572349068496989\n",
      "Ours base (binary: distortions only), log 0.4 0.5803202905728909 0.5892049127343244\n",
      "Ours base (binary: distortions only), log 0.5 0.3988773320125475 0.24003339595074097\n",
      "Ours base (binary: distortions only), log 0.6 0.345715700842001 0.10359647138656411\n",
      "Ours base (binary: distortions only), log 0.7 0.3151725276539541 0.020311761927255555\n",
      "Ours base (binary: distortions only), log 0.8 0.30807330361565133 0\n"
     ]
    }
   ],
   "source": [
    "for model in [m for m in models]:\n",
    "    print(model)\n",
    "    best_t = 0\n",
    "    best_acc = 0\n",
    "    best_f1 = 0\n",
    "    res_acc = {}\n",
    "    res_f1 = {}\n",
    "    for t in thresholds:\n",
    "        acc, f1 = evaluate_tm_df_acc_f1(df3,models[model],our_evaluator_tm_any,t,debug=False)\n",
    "        if acc > best_acc:\n",
    "            best_t = t\n",
    "            best_acc = acc\n",
    "            best_f1 = f1\n",
    "        res_acc[t] = acc\n",
    "        res_f1[t] = f1\n",
    "        print(model, t, acc, f1)\n",
    "    models_acc.append([round(res_acc[t],2) for t in thresholds])\n",
    "    models_f1.append([round(res_f1[t],2) for t in thresholds])\n",
    "    t0 = dt.datetime.now()\n",
    "    acc, f1 = evaluate_tm_df_acc_f1(df3,models[model],our_evaluator_tm_any,best_t,debug=False)\n",
    "    t1 = dt.datetime.now()\n",
    "    delta = t1 - t0\n",
    "    print(model, best_t, best_acc, best_f1, delta.total_seconds(), delta.total_seconds()/len(df3) )\n",
    "    models_results[model + ', any'] = ( 'any', best_t, best_acc, best_f1, delta.total_seconds(), delta.total_seconds()/len(df3) )\n",
    "assert len([r for r in models_results]) == len(models_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5972f6-3967-4798-b91e-12e1598bd8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [m for m in models if 'multi-class' in m]:\n",
    "    print(model)\n",
    "    best_t = 0\n",
    "    best_acc = 0\n",
    "    best_f1 = 0\n",
    "    res_acc = {}\n",
    "    res_f1 = {}\n",
    "    for t in thresholds:\n",
    "        acc, f1 = evaluate_tm_df_acc_f1(df3,models[model],our_evaluator_tm_avg,t,debug=False)\n",
    "        if acc > best_acc:\n",
    "            best_t = t\n",
    "            best_acc = acc\n",
    "            best_f1 = f1\n",
    "        res_acc[t] = acc\n",
    "        res_f1[t] = f1\n",
    "        print(model, t, acc, f1)\n",
    "    models_acc.append([round(res_acc[t],2) for t in thresholds])\n",
    "    models_f1.append([round(res_f1[t],2) for t in thresholds])\n",
    "    t0 = dt.datetime.now()\n",
    "    acc, f1 = evaluate_tm_df_acc_f1(df3,models[model],our_evaluator_tm_avg,best_t,debug=False)\n",
    "    t1 = dt.datetime.now()\n",
    "    delta = t1 - t0\n",
    "    print(model, best_t, best_acc, best_f1, delta.total_seconds(), delta.total_seconds()/len(df3) )\n",
    "    models_results[model + ', avg'] = ( 'avg', best_t, best_acc, best_f1, delta.total_seconds(), delta.total_seconds()/len(df3) )\n",
    "assert len([r for r in models_results]) == len(models_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32855dcb-89db-4db0-a970-3d141eb9a673",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in models_results:\n",
    "    print(models_results[result],model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31640407-62ed-457b-b225-5e5fef75f690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_plot(row_labels, col_labels, matrix, absmax, title = None, vmin = None, vmax = None, dpi = None, titlefontsize = None, width = 20):\n",
    "    plt.rcParams[\"figure.figsize\"] = (width,len(row_labels)/4)\n",
    "    if not dpi is None:\n",
    "        plt.rcParams[\"figure.dpi\"] = dpi\n",
    "    p = sns.heatmap(matrix, xticklabels=col_labels, yticklabels=row_labels, \n",
    "                    vmin = -absmax if vmin is None else vmin, \n",
    "                    vmax = absmax if vmax is None else vmax, \n",
    "                    cmap='RdYlGn', annot=True)\n",
    "    if title is not None:\n",
    "        if titlefontsize is None:\n",
    "            titlefontsize = 32 if len(title) < 50 else round(32 * 50 / len(title))\n",
    "        p.set_title(title,fontsize = titlefontsize)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "matrix_plot([m for m in models_results], thresholds, models_acc, 1.0, title = 'Accuracy for models and thresholds', \n",
    "            vmin = 1.0-(1.0-0.7)*2, vmax = 1.0, titlefontsize = 20, dpi = 200, width = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515a6f39-6b7c-4d8b-ba78-f084f8402afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_plot([m for m in models_results], thresholds, models_f1, 1.0, title = 'F1 for models and thresholds', \n",
    "            vmin = 1.0-(1.0-0.8)*2, vmax = 1.0, titlefontsize = 20, dpi = 200, width = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da0256b-73b5-49a1-9982-42c0c57a32f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models_results)):\n",
    "    model = [m for m in models_results][i]\n",
    "    row = models_acc[i]\n",
    "    maxt = 0\n",
    "    maxacc = 0\n",
    "    for col in range(len(row)):\n",
    "        if row[col] > maxacc:\n",
    "            maxacc = row[col]\n",
    "            maxt = thresholds[col]\n",
    "    if maxacc >= 0.8:\n",
    "        print(maxacc,maxt,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6245f4-be19-4776-b311-c9550e6af5f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63d3589-b247-48d3-b153-f4e1e50b0db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grand_t1 = dt.datetime.now()\n",
    "grand_delta = grand_t1 - grand_t0\n",
    "str(grand_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66846a18-3ac6-44c6-8d5d-7c80dd2f9695",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
