{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ File too large (572.59MB), reducing size...\n",
      "✅ Final dataset saved: Merged_Parquet/merged_sample.parquet (49.97MB, 21538 rows)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Paths\n",
    "input_folder = \"/replace_with_folder_path\"\n",
    "output_folder = \"Merged_Parquet\"\n",
    "output_file = os.path.join(output_folder, \"merged_sample.parquet\")\n",
    "os.makedirs(output_folder, exist_ok=True)  # Ensure output folder exists\n",
    "\n",
    "# Initialize list to store sampled data\n",
    "all_samples = []\n",
    "\n",
    "# Step 1: Sample 25% from each file\n",
    "for file in os.listdir(input_folder):\n",
    "    if file.endswith(\".parquet\"):\n",
    "        file_path = os.path.join(input_folder, file)\n",
    "        \n",
    "        # Read Parquet file\n",
    "        df = pd.read_parquet(file_path)\n",
    "        \n",
    "        # Randomly sample 25% of rows\n",
    "        df_sampled = df.sample(frac=0.25, random_state=42)\n",
    "        \n",
    "        all_samples.append(df_sampled)\n",
    "\n",
    "# Step 2: Merge all sampled data\n",
    "merged_df = pd.concat(all_samples, ignore_index=True)\n",
    "\n",
    "# Step 3: Reduce dataset if it exceeds 50MB\n",
    "max_size = 50 * 1024 * 1024  # 50MB in bytes\n",
    "temp_output = os.path.join(output_folder, \"temp.parquet\")\n",
    "\n",
    "# Save temp file to check size\n",
    "merged_df.to_parquet(temp_output, compression=\"zstd\", index=False)\n",
    "file_size = os.path.getsize(temp_output)\n",
    "\n",
    "# If file is larger than 50MB, downsample further\n",
    "if file_size > max_size:\n",
    "    print(f\"⚠️ File too large ({file_size / (1024 * 1024):.2f}MB), reducing size...\")\n",
    "    \n",
    "    # Calculate necessary fraction to stay under 50MB\n",
    "    fraction = max_size / file_size\n",
    "    merged_df = merged_df.sample(frac=fraction, random_state=42)  # Reduce further\n",
    "\n",
    "# Step 4: Sort by timestamp (if needed)\n",
    "if \"timestamp\" in merged_df.columns:\n",
    "    merged_df = merged_df.sort_values(by=\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "# Step 5: Save final Parquet file\n",
    "merged_df.to_parquet(output_file, compression=\"zstd\", index=False)\n",
    "\n",
    "# Remove temp file\n",
    "os.remove(temp_output)\n",
    "\n",
    "print(f\"✅ Final dataset saved: {output_file} ({os.path.getsize(output_file) / (1024 * 1024):.2f}MB, {len(merged_df)} rows)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema: timestamp: string\n",
      "title: string\n",
      "text: string\n",
      "concatenated_text: string\n",
      "source_file: string\n",
      "year_month: string\n",
      "-- schema metadata --\n",
      "pandas: '{\"index_columns\": [], \"column_indexes\": [], \"columns\": [{\"name\":' + 787\n",
      "Number of Rows: 21538\n",
      "\n",
      "🔍 Sample Data (Shuffled):\n",
      "      timestamp                                              title  \\\n",
      "2041    2024-04                                         1915年4月24日   \n",
      "5701    2024-05  WEEKLY REPORT - N.194 - Italy Community Update...   \n",
      "11942   2024-07                                        crystal liu   \n",
      "2150    2024-04                                        crystal liu   \n",
      "16778   2024-09  Daily top posts in category: poetry on 2024-09-01   \n",
      "\n",
      "                                                    text  \\\n",
      "2041   1915年4月24日，著名漫画家华君武出生。\\n华君武（1915年4月24日－2010年6月...   \n",
      "5701   ![2 (75).jpg](https://cdn.steemitimages.com/DQ...   \n",
      "11942        https://www.youtube.com/watch?v=MMyK6AW6u8Y   \n",
      "2150         https://www.youtube.com/watch?v=c5yWPsBJF3s   \n",
      "16778  <h2>Daily top posts in category: poetry on 202...   \n",
      "\n",
      "                                       concatenated_text  \\\n",
      "2041   1915年4月24日 . 1915年4月24日，著名漫画家华君武出生。\\n华君武（1915年...   \n",
      "5701   WEEKLY REPORT - N.194 - Italy Community Update...   \n",
      "11942  crystal liu . https://www.youtube.com/watch?v=...   \n",
      "2150   crystal liu . https://www.youtube.com/watch?v=...   \n",
      "16778  Daily top posts in category: poetry on 2024-09...   \n",
      "\n",
      "                           source_file year_month  \n",
      "2041   filtered_steemit_2024-04-23.csv    2024-04  \n",
      "5701   filtered_steemit_2024-05-30.csv    2024-05  \n",
      "11942  filtered_steemit_2024-07-26.csv    2024-07  \n",
      "2150   filtered_steemit_2024-04-17.csv    2024-04  \n",
      "16778  filtered_steemit_2024-09-01.csv    2024-09  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "parquet_file = ('/replace_with _path_to_file/merged_sample.parquet')\n",
    "    # Load Parquet file metadata\n",
    "table = pq.read_table(parquet_file)\n",
    "print(\"Schema:\", table.schema)\n",
    "print(\"Number of Rows:\", table.num_rows)\n",
    "\n",
    "    # Load into pandas and show a shuffled preview\n",
    "df = pd.read_parquet(parquet_file)\n",
    "print(\"\\n🔍 Sample Data (Shuffled):\")\n",
    "print(df.sample(min(5, len(df)), random_state=42))  # Show up to 10 rows, shuffled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>concatenated_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03</td>\n",
       "      <td>Diary Game for Monday,  18th March, 2024 | Upl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-03</td>\n",
       "      <td>Upvote . Upvoted. Thank You for sending some o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-03</td>\n",
       "      <td>Check my latest fight ! redwarrior vs  The Gov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-03</td>\n",
       "      <td>The Diary Game (27-03-24) De guardia en C.O 😁 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-03</td>\n",
       "      <td>Upvote . Upvoted. Thank You for sending some o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21533</th>\n",
       "      <td>2024-11</td>\n",
       "      <td>Me están esperando . &lt;div class=text-justify&gt; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21534</th>\n",
       "      <td>2024-11</td>\n",
       "      <td>А bambuka-то был прав . @@ -942,16 +942,17 @@\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21535</th>\n",
       "      <td>2024-11</td>\n",
       "      <td>보는 재미 . 코인시장이 활기를 보이고 있어 구경하는 재미가 있네요\\n특히 도지코인...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21536</th>\n",
       "      <td>2024-11</td>\n",
       "      <td>Israel Increases Pressure On Syria . ![Israel_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21537</th>\n",
       "      <td>2024-11</td>\n",
       "      <td>My Different Baby . &lt;p&gt;&lt;a href=https://cdn.pix...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21538 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp                                  concatenated_text\n",
       "0       2024-03  Diary Game for Monday,  18th March, 2024 | Upl...\n",
       "1       2024-03  Upvote . Upvoted. Thank You for sending some o...\n",
       "2       2024-03  Check my latest fight ! redwarrior vs  The Gov...\n",
       "3       2024-03  The Diary Game (27-03-24) De guardia en C.O 😁 ...\n",
       "4       2024-03  Upvote . Upvoted. Thank You for sending some o...\n",
       "...         ...                                                ...\n",
       "21533   2024-11  Me están esperando . <div class=text-justify> ...\n",
       "21534   2024-11  А bambuka-то был прав . @@ -942,16 +942,17 @@\\...\n",
       "21535   2024-11  보는 재미 . 코인시장이 활기를 보이고 있어 구경하는 재미가 있네요\\n특히 도지코인...\n",
       "21536   2024-11  Israel Increases Pressure On Syria . ![Israel_...\n",
       "21537   2024-11  My Different Baby . <p><a href=https://cdn.pix...\n",
       "\n",
       "[21538 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['title', 'text', 'source_file', 'year_month'], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tony Hawk’s American Wasteland Save File (PC Game Data) . <center><img decoding=\"async\" src=\"https://gamedl.download/savepics/tony-hawks-american-wasteland-cover.jpg\"/></center><p>If you want to simply download and install the Tony Hawk’s American Wasteland Save File (PC Game Data) for the game, just click the button bellow, run the exe file and your save data should be automatically loaded. You can know more about the game and the save file information bellow.</p>\\n<center><a href=\"https://gamedl.download/game-save-download\"><img src=\"https://gamedl.download/wp-content/uploads/2024/05/download.png\"/></a></center><p></p>\\n<ul>\\n<li>Developers: Neversoft</li>\\n<li>Release Date: October 18, 2005</li>\\n<li>Genres: Sports, Skateboarding</li>\\n<li>Platforms: PlayStation 2, Xbox, Xbox 360, GameCube, PC</li>\\n<li>Publisher: Activision</li>\\n</ul>\\n<h2>About Tony Hawk’s American Wasteland</h2>\\n<p>Tony Hawk’s American Wasteland is a skateboarding video game that marks a significant entry in the Tony Hawk series. Unlike its predecessors, it boasts a large, open-world environment that players can explore without encountering loading screens, simulating a seamless Los Angeles. This innovation allows for an immersive skateboarding experience, as players can skate from one end of the city to the other, discovering various skate parks and landmarks along the way.</p>\\n<p>The game introduces new mechanics and features, including BMX biking, which adds a fresh layer to the gameplay. The storyline follows the player's character, who travels to Los Angeles to become a skilled skateboarder. Along the journey, players meet and interact with various characters, complete missions, and unlock new areas and abilities. The game's narrative, combined with its expansive world and engaging gameplay, makes it a standout title in the series.</p>\\n<h2>Game Save Features</h2>\\n<ul>\\n<li><strong>Description</strong> – Game is completed 100% on all difficulty levels. Everything unlocked.</li>\\n<li><strong>Author</strong> – Kostia Gopov</li>\\n<li><strong>Example of savegame folder location</strong> – C:\\Program Files (x86)\\THAW\\Game\\Save</li>\\n</ul>\\n<h2>How to Download and Install Tony Hawk’s American Wasteland Game Save File with data in PC?</h2>\\n<ol>\\n<li>Click the download button bellow (or at the top of the page) to download the save file installer.</li>\\n<li>Follow the link instructions and enter a password if it's necessary, it's made to protect our servers from bot attacks.</li>\\n<li>Run the Installer, it's made to easily replace the game save and directly load the save into your game!</li>\\n<li>Enjoy! That's it, Tony Hawk’s American Wasteland Save file and all the Data should be automatically loaded the next time you run the game.</li>\\n</ol>\\n<center><a href=\"https://gamedl.download/game-save-download\"><img src=\"https://gamedl.download/wp-content/uploads/2024/05/download.png\"/></a></center><h2>More Game Saves</h2><ul><li><a href='https://steemit.com/download/@gamesave/tomb-raider-anniversary-save-file-pc-game-data'>Tomb Raider_ Anniversary Save</a></li><li><a href='https://steemit.com/download/@gamesave/tomb-raider-chronicles-save-file-pc-game-data'>Tomb Raider_ Chronicles Save</a></li><li><a href='https://steemit.com/download/@gamesave/tomb-raider-legend-save-file-pc-game-data'>Tomb Raider_ Legend Save</a></li><li><a href='https://steemit.com/download/@gamesave/tomb-raider-the-angel-of-darkness-save-file-pc-game-data'>Tomb Raider_ The Angel of Darkness Save</a></li><li><a href='https://steemit.com/download/@gamesave/tomb-raider-the-last-revelation-save-file-pc-game-data'>Tomb Raider_ The Last Revelation Save</a></li><li><a href='https://steemit.com/download/@gamesave/tomb-raider-underworld-save-file-pc-game-data'>Tomb Raider_ Underworld Save</a></li></ul>\n",
      "------------------------------\n",
      "바닥이 어딜지... . ![1000037372.jpg](https://cdn.steemitimages.com/DQmeHMdrBggvNiXMGSZfgXdvJBEYef7SPejvP7vPFZQQ9rV/1000037372.jpg)\\n\\n\\n이거 끝을 알수가 없네요ㅠ\n",
      "------------------------------\n",
      "পরিচয় পর্ব . আমি মেহেদী হাসান।\\nকেমন আছেন সবাই?\n",
      "------------------------------\n",
      "Upvote . Upvoted. Thank You for sending some of your rewards to @null. It will make Steem stronger.\n",
      "------------------------------\n",
      "আর্ট :- আমার বাংলা ব্লগ জন্মদিন উপলক্ষে সুন্দর আর্ট . <P><div class=\"text-justify\">\\n\\n\\n\\n <Center> <h2> হ্যালো বন্ধুরা,  </h2> </Center>\\n\\n সবাই কেমন আছেন। আশা করি আল্লাহর রহমতে সবাই ভাল আছেন। আলহামদুলিল্লাহ আমিও আল্লাহর রহমতে ভালো আছি। প্রথমেই সবাইকে জানাই আমার বাংলা ব্লগের জন্মদিনের অনেক অনেক শুভেচ্ছা। আমরা দেখতে দেখতে তিনটি বছর সবাই একসাথে কাটিয়ে ফেললাম। প্রথম বছরটা খুবই সুন্দরভাবে কাটিয়ে ছিলাম কিন্তু আজকে আবারো তৃতীয় বর্ষপূর্তি উপলক্ষে খুব সুন্দর মুহূর্ত অনুভব করতে যাচ্ছি। তাই আমিও সব মিলিয়ে চেষ্টা করেছি আমার নিজের মতো করে সুন্দরভাবে তৃতীয় বর্ষপূর্তি উপভোগ করার জন্য। \\n\\n\\nতাই আজকে আমি বাংলা ব্লগের জন্মদিন উপলক্ষে সুন্দর একটি আর্ট করার চেষ্টা করলাম। আসলে কম বেশি আমরা সবাই আমার বাংলা ব্লগকে ঘিরে বেশ সুন্দর কিছু করার চেষ্টা করি। তাই আজকে বিশেষ একটি দিনের আর্ট না করে আর পারলাম না। কারন আমার কাছে আর্ট করতে বেশ ভালোই লাগে। তাই যখনই সুযোগ পাই তখনই সুন্দর আর্টগুলো করার চেষ্টা করি। আর আজকে একটি বিশেষ দিনে আর্ট করবো না কি করে হয়। যাই হোক আমরা যেন এভাবেই সবাই একসাথে হাসি খুশিভাবে থাকতে পারি। আর আশা করি আমার করা এই আর্ট ও আপনাদেরও বেশ পছন্দ হবে।\\n\\n\\n\\n![IMG_20240611_220453.jpg](https://cdn.steemitimages.com/DQmZm6W57yKQdSjzNj1zsbAGmL9mvi29nTjJ1QQy6M9UUc6/IMG_20240611_220453.jpg)\\n\\n\\n\\n\\n <h2> আঁকার উপকরণ  </h2> \\n\\n\\n\\n\\n✓ আঁকার খাতা\\n✓ রং কলম \\n✓ পেন্সিল\\n✓ রাবার\\n✓ কাটার\\n✓ মার্কার\\n\\n\\n![IMG_20231118_194132.jpg](https://cdn.steemitimages.com/DQmdjQGYcUKUqZPxwtyw7zGxfW3dZivkeGFYXQPZitfMvZ9/IMG_20231118_194132.jpg)\\n\\n\\n <h2>  আঁকার বিবরণ :  </h2>\\n\\n  <h2>  ধাপ - ১ : </h2> \\n\\nপ্রথমে আমি আমার বাংলা ব্লগ এর জন্য একটি কেক এবং উপরে কিছু ডিজাইন পেন্সিল দিয়ে স্কেচ করে এঁকে নিয়ে নিলাম।\\n\\n\\n![IMG_20240611_223915.jpg](https://cdn.steemitimages.com/DQmUaZBC28VPR7W9J5uHr5R3e83FaA1rEe9ePwh99JV3nEu/IMG_20240611_223915.jpg)\\n\\n\\n  <h2>  ধাপ - ২ : </h2> \\n\\nতারপর নিচে একটি বড় কেক বিভিন্ন কালারের রং কলম দিয়ে সুন্দরভাবে রং করে নিয়ে নিলাম।\\n\\n\\n![IMG_20240611_223934.jpg](https://cdn.steemitimages.com/DQmYyXtpmba79zEUPfrf3H7CwdgwvDWPUhHudzbtpMrHkYo/IMG_20240611_223934.jpg)\\n\\n\\n  <h2>  ধাপ - ৩ : </h2> \\n\\n \\n\\nতারপর উপরের অংশে আমার বাংলা ব্লগ জন্মদিনের কিছুটা ডেকোরেশন করার জন্য বিভিন্ন কালার দিয়ে প্রথমে কালারফুল রং করে নিয়ে নিলাম।\\n\\n![IMG_20240611_223950.jpg](https://cdn.steemitimages.com/DQmPjPZwu4H8W5BtNJUXMYNZBDQG2UH7xsCWMYKrQ4PXdwF/IMG_20240611_223950.jpg)\\n\\n\\n  <h2>  ধাপ - ৪ : </h2> \\n\\n \\nসেই বিভিন্ন কালার গুলো চারপাশে কালো রং কলম দিয়ে চিকন দাগ টেনে সুন্দরভাবে রং করে নিয়ে নিলাম।\\n\\n![IMG_20240611_224002.jpg](https://cdn.steemitimages.com/DQmYPNVjWPDaqdDPfnfubwexCpiKoo3Hyr4qFJFj6ERC9Z4/IMG_20240611_224002.jpg)\\n\\n\\n  <h2>  ধাপ - ৫ : </h2> \\n\\n\\nতারপর সেই বক্স গুলোর মাঝখানে হ্যাপি বার্থডে আমার বাংলা ব্লগ মার্কার কলম দিয়ে লিখে নিয়ে নিলাম।\\n\\n\\n![IMG_20240611_224010.jpg](https://cdn.steemitimages.com/DQmPV9wfNyu1Wz1vR83tbCdREMyqZTcVL9hpGjcuSNP8rp9/IMG_20240611_224010.jpg)\\n\\n\\n  <h2>  ধাপ - ৬ : </h2> \\n\\nতারপর উদযাপন করার জন্য কিছু মানুষের ছায়া নিচের অংশে কালো করে রং করে নিয়ে নিলাম।\\n\\n\\n![IMG_20240611_224019.jpg](https://cdn.steemitimages.com/DQmfDYZJZTbdXoDQFPvn5vAzrCs1nm1125AWRpKjaw4FNTZ/IMG_20240611_224019.jpg)\\n\\n\\n  <h2>  ধাপ - ৭ : </h2> \\n\\n\\nতারপর চারপাশে কিছু আরও কালারফুল রং করে সুন্দরভাবে এই আর্ট সম্পন্ন করে নিয়ে নিলাম।\\n\\n![IMG_20240611_224027.jpg](https://cdn.steemitimages.com/DQmPV7heq48QdLMY1jVPCFoNMkU8oWa9AMVLA6Eh86QFpKN/IMG_20240611_224027.jpg)\\n\\n\\n  <h2>  শেষ ধাপ  : </h2> \\n\\n\\nএভাবে আমার বাংলা ব্লক জন্মদিন উপলক্ষে একটি সুন্দর আর্ট করলাম। আশা করি এই আর্ট আপনাদের সবার বেশ পছন্দ হবে। পরবর্তীতে আবারও দেখা হবে নতুন কিছু নিয়ে। সবাই ভালো থাকবেন।\\n\\n\\n\\n![IMG_20240611_220400.jpg](https://cdn.steemitimages.com/DQmdrHjnNUeZxdKQZbgZ636heQ2k5vHzGKBTsrSYGee769i/IMG_20240611_220400.jpg)\\n\\n![IMG_20240611_220453.jpg](https://cdn.steemitimages.com/DQmZm6W57yKQdSjzNj1zsbAGmL9mvi29nTjJ1QQy6M9UUc6/IMG_20240611_220453.jpg)\\n\\n![IMG_20240611_220435.jpg](https://cdn.steemitimages.com/DQmUcfZiACyAbazTCoQ3G7XEbCBdDWYv5q1kj9GPyPr5kkd/IMG_20240611_220435.jpg)\\n\\n\\n<P><div class=\"text-justify\">\\n\\n\\n\\n![JvFFVmatwWHRfvmtd53nmEJ94xpKydwmbSC5H5svBACH7xbS7ungTbMjNMsQ7fPnm8uUBT2bU8Azf8zCDQrq3tkzHjjCFyraxJQeY79tPTN45w8XxU9wtvaFmWRaLhgHSy5GYKQ6bg.png](https://cdn.steemitimages.com/DQmZrtBaknquDKAZVJ7EotUYiBtEi8GYEw3YFGssjPSwiho/JvFFVmatwWHRfvmtd53nmEJ94xpKydwmbSC5H5svBACH7xbS7ungTbMjNMsQ7fPnm8uUBT2bU8Azf8zCDQrq3tkzHjjCFyraxJQeY79tPTN45w8XxU9wtvaFmWRaLhgHSy5GYKQ6bg.png)\\n\\n\\n<div class=pull-left>\\n\\n![IMG-20211226-WA0000.jpg](https://cdn.steemitimages.com/DQmfZBt4rfoKL5cGZQwwfqsfvz1BtPtrpPZEbGao842nbuf/IMG-20211226-WA0000.jpg)\\n\\n</div>\\n\\n<div class=pull-right>\\n\\n</div>\\n\\nআমার নাম আকলিমা আক্তার মুনিয়া। আর আমার ইউজার নাম @bdwomen। আমি বাংলাদেশে বসবাস করি। বাংলা ভাষা হল আমাদের মাতৃভাষা আর আমি মাতৃভাষা বলতে পারি বলেই অনেক গর্বিত। আমি বিভিন্ন ধরনের ছবি এবং পেইন্টিং আঁকতে খুবই পছন্দ করি। আমি প্রায় সময় বিভিন্ন ধরনের পেইন্টিং এঁকে থাকি। আবার রঙিন পেপার এবং বিভিন্ন রকমের জিনিস দিয়ে নানা ধরনের কারুকাজ তৈরি করতে আমার খুবই ভালো লাগে। আবার নিজের বিভিন্ন জায়গায় গিয়ে ছবি তুলতে খুবই ভালো লাগে। আমি চেষ্টা করি সব ধরনের জিনিস কখনো না কখনো একবার করে করার জন্য। আবার বিভিন্ন ধরনের আইডিয়া মাথায় আসলে সেগুলো ও করার চেষ্টা করি।\\n\\n![35FHZ8gBpndbrF88KC8i6DmfoqNdVfSnhzJshZCJksDJs27YpCCUjp1oaP6ko3mLJbQtLE76ZKc5r3aFXKh8EK2Xg2XbxHP97436Dksrat...K3RRDcGvdyC6bx3TE39Zctd2ho1pJ1hm9nj6RC6gfhhSEVDEf6zHmiqsgBwDTEDG8onxfxrWKe5ZMmiwAvtnX6XvsCqykCT5aFqMFBq2wcdKNs74j1RgTuza3g.png](https://cdn.steemitimages.com/DQmUp3m2ADFi4F1WPZNBEEsgwDoh1L3T54demzmo9ZBqnZD/35FHZ8gBpndbrF88KC8i6DmfoqNdVfSnhzJshZCJksDJs27YpCCUjp1oaP6ko3mLJbQtLE76ZKc5r3aFXKh8EK2Xg2XbxHP97436Dksrat...K3RRDcGvdyC6bx3TE39Zctd2ho1pJ1hm9nj6RC6gfhhSEVDEf6zHmiqsgBwDTEDG8onxfxrWKe5ZMmiwAvtnX6XvsCqykCT5aFqMFBq2wcdKNs74j1RgTuza3g.png)\\n\\n\\n![A5tMjLhTTnj4UJ3Q17DFR9PmiB5HnomwsPZ1BrfGqKbjde9gvbjDSDFUe2t87sHycAo9yh4cXNBQ2uKuZLC2jPzA8Qx5HRSqkJDxCm2F1P...XMCuWWrUK8WEzc1spvbtGymKcxp9cSaiY7YD7nmGv2yy3TJjQK1R5Bx6mMsJqHLdPZ4gBXB1M3ZGWR3ESWZxh8hd9tvb68pfdL8xHrioiqDnHuRUqd8FYt5aog.png](https://cdn.steemitimages.com/DQmYjB9U1MmkQgB6tTvuGJVRAsDHvgDcMdTnUd9X7DrVVjr/A5tMjLhTTnj4UJ3Q17DFR9PmiB5HnomwsPZ1BrfGqKbjde9gvbjDSDFUe2t87sHycAo9yh4cXNBQ2uKuZLC2jPzA8Qx5HRSqkJDxCm2F1P...XMCuWWrUK8WEzc1spvbtGymKcxp9cSaiY7YD7nmGv2yy3TJjQK1R5Bx6mMsJqHLdPZ4gBXB1M3ZGWR3ESWZxh8hd9tvb68pfdL8xHrioiqDnHuRUqd8FYt5aog.png)\\n\\n\\n</div></p>\\n\\n\\n\\n<center> <h2> ধন্যবাদ সবাইকে  </h2> </center>\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "random_rows = df.sample(5)\n",
    "for index, row in random_rows.iterrows():\n",
    "    print(row['concatenated_text'])\n",
    "    print(\"------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[',', 'the', '.', 'and', 'to', 'of', 'a', '</s>', 'in', 'is']\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "model_path = '/Replace_with_path_to/cc.en.300.bin'\n",
    "\n",
    "\n",
    "model = fasttext.load_model('/Replace_with_your_model_path/cc.en.300.bin')\n",
    "\n",
    "print(model.words[:10])  # Show first 10 words in the vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output folders\n",
    "input_folder = \"/Replace_with_your_path/Merged_Parquet\"\n",
    "output_folder = \"Cleaned_Files\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed: merged_sample.parquet\n",
      "🎉 FastText cleaning completed!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Function to clean text with FastText\n",
    "def process_text(text):\n",
    "    \"\"\"Removes unwanted characters and keeps only words in FastText vocabulary.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"  # Handle non-string values\n",
    "\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Keep only letters and spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word in model.words]  # Keep only known words\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "# Process each Parquet file\n",
    "for parquet_file in os.listdir(input_folder):\n",
    "    if parquet_file.endswith(\".parquet\"):\n",
    "        input_path = os.path.join(input_folder, parquet_file)\n",
    "        output_path = os.path.join(output_folder, parquet_file)  # Save with same name\n",
    "\n",
    "        # Read the dataset\n",
    "        df = pd.read_parquet(input_path, columns=[\"timestamp\", \"concatenated_text\"])\n",
    "\n",
    "        # Apply text cleaning\n",
    "        df[\"processed_text\"] = df[\"concatenated_text\"].apply(process_text)\n",
    "\n",
    "        # Drop the original column\n",
    "        df = df[[\"timestamp\", \"processed_text\"]]\n",
    "\n",
    "        # Save cleaned data\n",
    "        df.to_parquet(output_path, index=False)\n",
    "\n",
    "        # Free memory\n",
    "        del df\n",
    "        gc.collect()\n",
    "\n",
    "        print(f\"✅ Processed: {parquet_file}\")\n",
    "\n",
    "print(\"🎉 FastText cleaning completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03</td>\n",
       "      <td>Diary Game for Monday th March Uploaded my boo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-03</td>\n",
       "      <td>Upvote Upvoted Thank You for sending some of y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-03</td>\n",
       "      <td>Check my latest fight vs The Goverment a href src</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-03</td>\n",
       "      <td>The Diary Game De guardia en CO Steemit Y los ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-03</td>\n",
       "      <td>Upvote Upvoted Thank You for sending some of y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  timestamp                                     processed_text\n",
       "0   2024-03  Diary Game for Monday th March Uploaded my boo...\n",
       "1   2024-03  Upvote Upvoted Thank You for sending some of y...\n",
       "2   2024-03  Check my latest fight vs The Goverment a href src\n",
       "3   2024-03  The Diary Game De guardia en CO Steemit Y los ...\n",
       "4   2024-03  Upvote Upvoted Thank You for sending some of y..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_parquet('/Replace_with_your_path/merged_sample.parquet')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21538,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rows_count = df1.shape[:1]\n",
    "rows_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargar Farming Simulator PC Gratis Directo y Torrent Farming Simulator PC juego gratis en espaol directamente o a de Torrent La del juego est para una descarga e y que los tiempos de ms posibles Puedes acceder a Farming Simulator a de los enlaces directos o torrent que te a todos ellos seguros libres de cracks y sin tipo de virus Slo tienes que pulsar el botn de descarga el archivo de y seguir las instrucciones que se postid src de agricultura de de noviembre de href de descarga src del Simulator te permite en un moderno construir y tu granja en tres lugares diferentes de Amrica y Europa El juego tiene muchas actividades como cultivar cuidar animales y talar Ahora puedes experimentar diferentes estaciones en el ms de y herramientas de ms de marcas reales como John Deere CLAAS y New Holland Puedes cultivar como trigo maz patatas y Nuevos tipos de y hacen que el juego sea an ms divertido e puedes jugar con amigos en el modo Hay muchas por la comunidad que puedes agregar al juego Farming Simulator te ofrece ms libertad que nunca Te a en un Entonces comienza tu aventura y disfruta de los buenos del un procesador y un sistema operativo de Windows Inicio Intel Core i o AMD FX o GB de GeForce GTX o AMD Radeon R o superior GB de de Internet de banda GB de espacio de Tarjeta de Estos requisitos del sistema no pueden todas las posibles del sistema por lo que problemas que en la en algunos de src src e instalar Farming Simulator para PC clic en el enlace de descarga situado en la parte superior de la o ms abajo directa o enlaces de descarga en pocos segundos la versin del juego la del servidor de descarga ms cercano para obtener la versin de la manera ms uno de los enlaces de descarga de la de descargas y sigue las instrucciones de la est el del juego te asegurar la descarga del Farming Simulator desde nuestros ms cercanos y el juego se instalar en tu href Farming Simulator botn src juegos de PC para href Father Save the href href href Simulator href Simulator href Simulator Titanium\n",
      "------------------------------\n",
      "h nnn sub h device note h sub sub center n n Redmi note n as rme as your Center h h Center\n",
      "------------------------------\n",
      "Bold Bitcoin predictions There have been many quite bold bullish predictions about the future of Bitcoin in the last doubt the most of them are just plain shilling but to tell you the truth I believe the most of them are future will tell of course but buying more Bitcoin has always played well for those who Check out my post from yesterday for some reference if you want more solid is once again being traded around the value of the Bitcoin Enjoying Strongest Bullish Sentiment in has recorded powerful sentiment jump after its price DOGE and Among Top Laggards as Crypto Market Remains in meme coins are underperforming will Dogecoin manage to stage Michael Saylors Epic Bitcoin BTC Price Prediction Stuns Crypto Saylor makes bold call on Bitcoin price amid short term Peter Schiff Accidentally Endorses Bitcoin n Peter Schiff secretly promoting Bitcoin nn Dogecoins DOGE Golden Cross Potential Bitcoins BTC Comeback Solanas SOL Big Breakthrough keeps growth potential and may regain some serious ground for Million XRP Withdrawal Stuns Largest Crypto Exchange community witnessed massive XRP outflow from within short period of Bitcoin BTC Prediction for July n Bitcoin BTC have energy to rise next Cardano Founder Makes Unexpected Bitcoin highlighted his longstanding involvement with ADA and SOL Prediction for July n Cardano ADA and Solana SOL remain bullish for long Shiba Inus on Verge of Million Blocks Inu Layer on verge of major milestone ahead of first Shiba Inu Burn Rate Jumps as Enters Epic Rebound Moden Inu eyes sustained rebound as burn rate Chainlink LINK Price Might Skyrocket If This Pattern Plays price might be forming head and shoulders Community Alert Key Message From Shiba Inu Inu team member drops key message for community as anticipation Billion Asset Manager Hamilton Lane Floats Massive Fund on Lane just validated Solana with new Elon Musk Responds to Bitcoin El Salvador President Nayib Vital Musk has engaged himself in discussion with president of Bitcoin state El Peter Schiff Reveals Unexpected Fact About Bitcoin Schiff reveals that he has looked into Bitcoin in past just as other smart Legendary Trader Peter Brandt Fires Back at Schiffs Bitcoin comments on Bitcoin had caught attention of legendary trader Peter No US Dollar by Samson Mow Reacts to Michael Saylors Epic vs USD Samson Mow has made his Shiba Inu to Escape Bad History This Inu struggles but might pull monthly Ethereum Creator Vitalik Buterin Debunks ETH Centralization founder Vitalik Buterin has responded to recent claims of centralization of ETH Here are some of our favorite quotes to motivate you to not give up and keep up the good Success isnt always about greatness Its about consistency Consistent hard work leads to success Greatness will come Dwayne Success seems to be connected with action Successful people keep moving They make mistakes but they dont Conrad Character cannot be developed in ease and quiet Only through experience of trial and suffering can the soul be strengthened vision cleared ambition inspired and success Helen Ive come to believe that each of us has a personal calling thats as unique as a fingerprint and that the best way to succeed is to discover what you love and then find a way to offer it to others in the form of service working hard and also allowing the energy of the universe to lead Oprah Most of the important things in the world have been accomplished by people who have kept on trying when there seemed to be no hope at Dale journey here continues and we hope to find lots of new friends and interesting content and accounts on you got up to this point please receive some positive vibes and thoughts from us Have a great Copyright by a href from a href\n",
      "------------------------------\n",
      "Lovely HOT Flower Posts on Aug my dear this post I share the latest hot posts about flower I love the beauty of flower and I know most of are loving to share variety of the beautiful of flower so I come out with this post and gather all in one place This is very hot flower topic on the STEEM blockchain for August nn a href by src a href a by src a href PHOTOGRAPHY BY by src a href flower photo of by src a href flower by src a href photography sunflower terry This is definitely not a by src a href photography posta by src a href a by src a href Lovely HOT Flower Posts on Auga by src a href by src The info is taken from the Steem database at August\n",
      "------------------------------\n",
      "The Adorable Fish pa href img src appThe Adorable Fish always had with them a pint of beer that they would often rub on his belly This could be considered a fairly weird and wonderful operation to my grandpa but not to the Fish who had decided it was wonderful Strangely a pint of beer is the thing that was Adorable Fish looked for a set of lego that they would throw It might have been an extraordinary undertaking to my grandpa but not to the Fish who felt that the idea was miraculous You wouldnt have thought a set of lego is the thing to opt Adorable Fish desperately looked for a rubber johnny that they liked to rub on his belly It should have been a peculiar activity to me and my wife but not to the Fish who thought it would be wonderful Strangely a rubber johnny would be the item that was opted Adorable Fish had a stapler that they liked to watch for minutes every morning One might consider this to be a fairly astonishing idea to many but not to the Fish who thinks that this idea is sublime You wouldnt have thought a stapler would be the thing that was Adorable Fish desperately desired a that they would smash It should have been a fairly bizarre idea to me and my husband but not to the Fish who had come to the conclusion that this idea is Who would have imagined a being the item opted Adorable Fish desperately searched for a bottle of wine that they would put in the bath with him One might find this to be a fairly exciting thing to do to me and my parents but not to the Fish who felt that the idea was fun Bizarrely a bottle of wine would be the item that was\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "random_rows = df1.sample(5)\n",
    "for index, row in random_rows.iterrows():\n",
    "    print(row['processed_text'])\n",
    "    print(\"------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Different Baby pa href img src Different Baby owned a block of cheese that\n",
      "they would sometimes embrace This seems a fairly peculiar undertaking to many\n",
      "but not to the Baby who had come to the conclusion that the idea was miraculous\n",
      "Bizarrely a block of cheese having that done to Different Baby desperately\n",
      "searched for a Harry Potter wand that they liked to hug This might appear to be\n",
      "a fairly exciting activity to many but not to the Baby who expected that this\n",
      "idea is wonderful Who would have imagined a Harry Potter wand being the thing\n",
      "opted Different Baby had a pen to hug It is considered to be a surprising\n",
      "exercise to everybody you know but not to the Baby who felt that the idea was\n",
      "the most awesome idea You wouldnt have imagined a pen being the chosen Different\n",
      "Baby always had with them a pen that they sometimes cuddle It was considered to\n",
      "be an original operation to my children but not to the Baby who had decided that\n",
      "the idea was miraculous A pen having that done to Different Baby needed a sack\n",
      "of potatoes that they would occasionally sit and look at One might say this is a\n",
      "fairly odd thing to do to many but not to the Baby who thought that it was in\n",
      "fact miraculous Honestly a sack of potatoes would be the thing that was\n",
      "Different Baby wanted a Harry Potter wand that they liked to try to nail to the\n",
      "wall This seems to be a fairly bizarre action to my dad but not to the Baby who\n",
      "had decided that the idea was wonderful A Harry Potter wand would be the item\n",
      "that was opted forp\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "text = df1.loc[21537, 'processed_text']\n",
    "wrapped_text = textwrap.fill(text, width=80)\n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Different Baby . <p><a href=https://cdn.pixabay.com/photo/2021/04/27/16/12/su\n",
      "cculents-6211878_960_720.png ><img src=https://cdn.pixabay.com/photo/2021/04/27/\n",
      "16/12/succulents-6211878_960_720.png /></a></p><p>My Different Baby owned a\n",
      "block of cheese that they would sometimes embrace. This seems a fairly peculiar\n",
      "undertaking, to many, but not to the  Baby, who  had come to the conclusion that\n",
      "the idea was miraculous. Bizarrely, a block of cheese having that done to\n",
      "it</p><p>My Different Baby desperately searched for a Harry Potter wand that\n",
      "they liked to hug. This might appear to be a fairly exciting activity, to many,\n",
      "but not to the  Baby, who  expected that this idea is wonderful. Who would have\n",
      "imagined, a Harry Potter wand being the thing opted for.</p><p>My Different Baby\n",
      "had a pen to hug. It is considered to be a surprising exercise, to everybody you\n",
      "know, but not to the  Baby, who  felt that the idea was the most awesome idea.\n",
      "You wouldnt have imagined, a pen being the chosen item.</p><p>My Different Baby\n",
      "always had with them a pen that they sometimes cuddle. It was considered to be\n",
      "an original operation, to my children, but not to the  Baby, who  had decided\n",
      "that the idea was miraculous. A pen having that done to it</p><p>My Different\n",
      "Baby needed a sack of potatoes that they would occasionally sit and look at. One\n",
      "might say this is a fairly odd thing to do, to many, but not to the  Baby, who\n",
      "thought that it was in fact, miraculous. Honestly, a sack of potatoes would be\n",
      "the thing that was chosen.</p><p>My Different Baby wanted a Harry Potter wand\n",
      "that they liked to try to nail to the wall. This seems to be a fairly bizarre\n",
      "action, to my dad, but not to the  Baby, who  had decided that the idea was\n",
      "wonderful. A Harry Potter wand would be the item that was opted for.</p>\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "text = df.loc[21537, 'concatenated_text']\n",
    "wrapped_text = textwrap.fill(text, width=80)\n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. ### SENTIMENT ANALYSIS AND ATTACH SENTIMENT SCORES AND SENTIMENT CATEGORIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal in this stage is to have topics that can have some meaning as the predicted topics will be evaluated against the sentiment scores \n",
    "abd lebels. The topics are also to be defined and compared based on the sentiment characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1340b1830>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "torch.manual_seed(44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sentiment analysis model and tokenizer\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "model = BertForSequenceClassification.from_pretrained(model_name).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Define input/output directories\n",
    "input_folder = \"/Users/Replace_with_your_path/Cleaned_Files\"\n",
    "output_folder = \"Bert_Sentiment_Results\"\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset Class\n",
    "class SentimentDataset(Dataset):\n",
    "    \"\"\"Dataset class for sentiment analysis.\"\"\"\n",
    "    def __init__(self, dataframe, tokenizer, max_length=512):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data.iloc[idx]['processed_text']\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0)\n",
    "        }\n",
    "\n",
    "# Function to analyze sentiment\n",
    "def analyze_sentiment_batch(batch):\n",
    "    \"\"\"Analyze sentiment for a batch of text inputs.\"\"\"\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "    predictions = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch: 100%|██████████| 63/63 [25:16<00:00, 24.07s/it]\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_score'] = predictions  # Use .loc to avoid the warning\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_category'] = chunk['sentiment_score'].apply(lambda x: {\n",
      "Processing batch: 100%|██████████| 63/63 [25:32<00:00, 24.32s/it]\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_score'] = predictions  # Use .loc to avoid the warning\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_category'] = chunk['sentiment_score'].apply(lambda x: {\n",
      "Processing batch: 100%|██████████| 63/63 [26:45<00:00, 25.48s/it]\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_score'] = predictions  # Use .loc to avoid the warning\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_category'] = chunk['sentiment_score'].apply(lambda x: {\n",
      "Processing batch: 100%|██████████| 63/63 [25:30<00:00, 24.29s/it]\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_score'] = predictions  # Use .loc to avoid the warning\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_category'] = chunk['sentiment_score'].apply(lambda x: {\n",
      "Processing batch: 100%|██████████| 63/63 [25:25<00:00, 24.21s/it]\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_score'] = predictions  # Use .loc to avoid the warning\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_category'] = chunk['sentiment_score'].apply(lambda x: {\n",
      "Processing batch: 100%|██████████| 63/63 [25:07<00:00, 23.93s/it]\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_score'] = predictions  # Use .loc to avoid the warning\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_category'] = chunk['sentiment_score'].apply(lambda x: {\n",
      "Processing batch: 100%|██████████| 63/63 [28:28<00:00, 27.12s/it]\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_score'] = predictions  # Use .loc to avoid the warning\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_category'] = chunk['sentiment_score'].apply(lambda x: {\n",
      "Processing batch: 100%|██████████| 63/63 [25:04<00:00, 23.88s/it]\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_score'] = predictions  # Use .loc to avoid the warning\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_category'] = chunk['sentiment_score'].apply(lambda x: {\n",
      "Processing batch: 100%|██████████| 63/63 [25:17<00:00, 24.09s/it]\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_score'] = predictions  # Use .loc to avoid the warning\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_category'] = chunk['sentiment_score'].apply(lambda x: {\n",
      "Processing batch: 100%|██████████| 63/63 [24:27<00:00, 23.29s/it]\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_score'] = predictions  # Use .loc to avoid the warning\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_category'] = chunk['sentiment_score'].apply(lambda x: {\n",
      "Processing batch: 100%|██████████| 63/63 [25:25<00:00, 24.22s/it]\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_score'] = predictions  # Use .loc to avoid the warning\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_category'] = chunk['sentiment_score'].apply(lambda x: {\n",
      "Processing batch: 100%|██████████| 63/63 [24:58<00:00, 23.79s/it]\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_score'] = predictions  # Use .loc to avoid the warning\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_category'] = chunk['sentiment_score'].apply(lambda x: {\n",
      "Processing batch: 100%|██████████| 63/63 [23:14<00:00, 22.13s/it]\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_score'] = predictions  # Use .loc to avoid the warning\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_category'] = chunk['sentiment_score'].apply(lambda x: {\n",
      "Processing batch: 100%|██████████| 63/63 [23:35<00:00, 22.46s/it]\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_score'] = predictions  # Use .loc to avoid the warning\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_category'] = chunk['sentiment_score'].apply(lambda x: {\n",
      "Processing batch: 100%|██████████| 63/63 [24:46<00:00, 23.59s/it]\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_score'] = predictions  # Use .loc to avoid the warning\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_category'] = chunk['sentiment_score'].apply(lambda x: {\n",
      "Processing batch: 100%|██████████| 63/63 [22:11<00:00, 21.14s/it]\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_score'] = predictions  # Use .loc to avoid the warning\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_category'] = chunk['sentiment_score'].apply(lambda x: {\n",
      "Processing batch: 100%|██████████| 63/63 [24:37<00:00, 23.45s/it]\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_score'] = predictions  # Use .loc to avoid the warning\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_category'] = chunk['sentiment_score'].apply(lambda x: {\n",
      "Processing batch: 100%|██████████| 63/63 [24:17<00:00, 23.13s/it]\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_score'] = predictions  # Use .loc to avoid the warning\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_category'] = chunk['sentiment_score'].apply(lambda x: {\n",
      "Processing batch: 100%|██████████| 63/63 [25:54<00:00, 24.68s/it]\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_score'] = predictions  # Use .loc to avoid the warning\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_category'] = chunk['sentiment_score'].apply(lambda x: {\n",
      "Processing batch: 100%|██████████| 63/63 [26:13<00:00, 24.98s/it]\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_score'] = predictions  # Use .loc to avoid the warning\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_category'] = chunk['sentiment_score'].apply(lambda x: {\n",
      "Processing batch: 100%|██████████| 63/63 [23:55<00:00, 22.78s/it]\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_score'] = predictions  # Use .loc to avoid the warning\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_category'] = chunk['sentiment_score'].apply(lambda x: {\n",
      "Processing batch: 100%|██████████| 34/34 [12:55<00:00, 22.80s/it]\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_score'] = predictions  # Use .loc to avoid the warning\n",
      "/var/folders/2n/32f7yt256q58tgb5vkg7g1zm0000gn/T/ipykernel_1773/1405933083.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chunk.loc[:, 'sentiment_category'] = chunk['sentiment_score'].apply(lambda x: {\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed /Users/samsonbobo/Desktop/Research Topic/Thesis/Cleaned_Files/merged_sample.parquet → Saved to Bert_Sentiment_Results/merged_sample_sentiment.csv\n",
      "✅ Sentiment analysis completed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to process each cleaned Parquet file\n",
    "def process_parquet_file(parquet_path):\n",
    "    output_path = os.path.join(output_folder, os.path.basename(parquet_path).replace(\".parquet\", \"_sentiment.csv\"))\n",
    "    \n",
    "    df = pd.read_parquet(parquet_path)\n",
    "\n",
    "    chunk_size = 1000  # Adjust based on memory capacity\n",
    "    first_chunk = True\n",
    "\n",
    "    for start in range(0, len(df), chunk_size):\n",
    "        chunk = df.iloc[start:start+chunk_size]\n",
    "\n",
    "        dataset = SentimentDataset(chunk, tokenizer)\n",
    "        dataloader = DataLoader(dataset, batch_size=16, shuffle=False, collate_fn=lambda x: {\n",
    "            'input_ids': torch.stack([item['input_ids'] for item in x]),\n",
    "            'attention_mask': torch.stack([item['attention_mask'] for item in x])\n",
    "        })\n",
    "\n",
    "        predictions = []\n",
    "        for batch in tqdm(dataloader, desc=\"Processing batch\"):\n",
    "            batch_predictions = analyze_sentiment_batch(batch)\n",
    "            predictions.extend(batch_predictions)\n",
    "\n",
    "        chunk.loc[:, 'sentiment_score'] = predictions  # Use .loc to avoid the warning\n",
    "        chunk.loc[:, 'sentiment_category'] = chunk['sentiment_score'].apply(lambda x: {\n",
    "    0: 'negative',\n",
    "    1: 'negative',\n",
    "    2: 'neutral',\n",
    "    3: 'positive',\n",
    "    4: 'positive'\n",
    "}.get(x))\n",
    "        \n",
    "        if first_chunk:\n",
    "            chunk.to_csv(output_path, mode='w', index=False)\n",
    "            first_chunk = False\n",
    "        else:\n",
    "            chunk.to_csv(output_path, mode='a', index=False, header=False)\n",
    "\n",
    "        del chunk\n",
    "        gc.collect()\n",
    "\n",
    "    print(f\"Processed {parquet_path} → Saved to {output_path}\")\n",
    "\n",
    "# Process all cleaned text files\n",
    "for parquet_file in os.listdir(input_folder):\n",
    "    if parquet_file.endswith(\".parquet\"):\n",
    "        process_parquet_file(os.path.join(input_folder, parquet_file))\n",
    "\n",
    "print(\"✅ Sentiment analysis completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03</td>\n",
       "      <td>Diary Game for Monday th March Uploaded my boo...</td>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-03</td>\n",
       "      <td>Upvote Upvoted Thank You for sending some of y...</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-03</td>\n",
       "      <td>Check my latest fight vs The Goverment a href src</td>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-03</td>\n",
       "      <td>The Diary Game De guardia en CO Steemit Y los ...</td>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-03</td>\n",
       "      <td>Upvote Upvoted Thank You for sending some of y...</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  timestamp                                     processed_text  \\\n",
       "0   2024-03  Diary Game for Monday th March Uploaded my boo...   \n",
       "1   2024-03  Upvote Upvoted Thank You for sending some of y...   \n",
       "2   2024-03  Check my latest fight vs The Goverment a href src   \n",
       "3   2024-03  The Diary Game De guardia en CO Steemit Y los ...   \n",
       "4   2024-03  Upvote Upvoted Thank You for sending some of y...   \n",
       "\n",
       "   sentiment_score sentiment_category  \n",
       "0                4           positive  \n",
       "1                0           negative  \n",
       "2                4           positive  \n",
       "3                4           positive  \n",
       "4                0           negative  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('/Users/Replace_with_your_path/merged_sample_sentiment.csv')\n",
    "df2.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
