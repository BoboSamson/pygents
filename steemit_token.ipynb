{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30ffea5-a09c-40ae-a34f-f0e942db3c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a399525-9180-46e1-8fdb-b2c776c98f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import spacy\n",
    "\n",
    "# Load SpaCy's language model (for POS tagging)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Function to tokenize and filter words based on POS tags and additional rules\n",
    "def tokenize_and_filter(text):\n",
    "    \"\"\"\n",
    "    Tokenize and filter words based on POS tags and additional rules.\n",
    "    Includes verbs, adjectives, and nouns, excluding pronouns.\n",
    "    Excludes symbols, single letters, and non-alphabetic tokens.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = [\n",
    "        token.text.lower() for token in doc\n",
    "        if token.pos_ in {\"VERB\", \"ADJ\", \"NOUN\"}  # Select specific POS tags\n",
    "        and token.tag_ not in {\"PRP\", \"PRP$\"}     # Exclude pronouns\n",
    "        and len(token.text) > 1                   # Exclude single characters\n",
    "        and token.text.isalpha()                  # Exclude non-alphabetic tokens\n",
    "    ]\n",
    "    return filtered_tokens\n",
    "\n",
    "# Function to update the word frequency dictionary\n",
    "def update_word_count(word_counter, tokens):\n",
    "    \"\"\"Update the word count Counter with tokens.\"\"\"\n",
    "    word_counter.update(tokens)\n",
    "\n",
    "# Function to plot and save a bar chart from a dictionary\n",
    "def save_bar_plot(data_dict, x_label, y_label, title, output_path, show=False):\n",
    "    \"\"\"\n",
    "    Plot a bar chart from a dictionary and save it as an image file.\n",
    "    Optionally display the plot in the notebook.\n",
    "    \"\"\"\n",
    "    # Sort the dictionary and take the top 10 tokens\n",
    "    sorted_items = sorted(data_dict.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "    words, counts = zip(*sorted_items) if sorted_items else ([], [])  # Handle empty case\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(words, counts, color=\"skyblue\")\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    plt.gca().invert_yaxis()  # Invert the y-axis for better readability\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot to the specified file path\n",
    "    plt.savefig(output_path)\n",
    "    \n",
    "    # Optionally show the plot\n",
    "    if show:\n",
    "        plt.show()\n",
    "    \n",
    "    # Close the figure to free memory\n",
    "    plt.close()\n",
    "\n",
    "# Paths for input and output\n",
    "output_folder = \"steemit_tsv_filtered_output\"\n",
    "output_file = \"word_frequencies.csv\"\n",
    "plots_folder = \"bar_plots\"\n",
    "\n",
    "# Ensure the output folder for plots exists\n",
    "os.makedirs(plots_folder, exist_ok=True)\n",
    "\n",
    "# Initialize a Counter for word counts\n",
    "word_counter = Counter()\n",
    "\n",
    "# Open a file to save word frequencies\n",
    "with open(output_file, \"w\") as outfile:\n",
    "    outfile.write(\"word,count\\n\")  # Write header\n",
    "\n",
    "    # Loop through each file in the output folder\n",
    "    for i, file_name in enumerate(os.listdir(output_folder)):\n",
    "        if file_name.endswith(\".csv\"):\n",
    "            file_path = os.path.join(output_folder, file_name)\n",
    "            \n",
    "            # Read the file\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Initialize a Counter for the current file\n",
    "            file_word_counter = Counter()\n",
    "            \n",
    "            # Tokenize and filter the \"text\" column\n",
    "            for text in df[\"text\"].dropna():\n",
    "                tokens = tokenize_and_filter(text)\n",
    "                update_word_count(word_counter, tokens)\n",
    "                update_word_count(file_word_counter, tokens)\n",
    "                \n",
    "                # Write word frequencies to the cumulative file incrementally\n",
    "                for word, count in Counter(tokens).items():\n",
    "                    outfile.write(f\"{word},{count}\\n\")\n",
    "            \n",
    "            # Generate and save a bar plot for the current file\n",
    "            plot_file_name = f\"{os.path.splitext(file_name)[0]}_bar_plot.png\"\n",
    "            plot_file_path = os.path.join(plots_folder, plot_file_name)\n",
    "            \n",
    "            # Show the bar plot only for the first file\n",
    "            save_bar_plot(\n",
    "                file_word_counter,\n",
    "                x_label=\"Word\",\n",
    "                y_label=\"Count\",\n",
    "                title=f\"Top Words in {file_name}\",\n",
    "                output_path=plot_file_path,\n",
    "                show=(i == 0)  # Show only for the first file\n",
    "            )\n",
    "\n",
    "print(f\"Word frequencies saved to '{output_file}'.\")\n",
    "print(f\"Bar plots saved to the '{plots_folder}' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0b33b1-70b8-4c87-8ac2-9ea7e0a2301b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
