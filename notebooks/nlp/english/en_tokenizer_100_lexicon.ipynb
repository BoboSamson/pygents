{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82c06628",
   "metadata": {},
   "source": [
    "# Exploring English Lexicon-based Tokenizer\n",
    "\n",
    "- Top F1=0.99 with delimiting symbols added to the lexicon (same as Freedom-based top F1=0.99)\n",
    "- Top F1 based on length-driven parsing, not weight-driven or \"hybrid\" (legth-times-logweight-driven)\n",
    "- Errors (0.6) are due to unknown words (mostly like \"it's\" missed in the dictinary)\n",
    "- Not adding delimiters to lexicon drops top F1 to 0.94\n",
    "- Adding threshold on word freqency does not improve F1\n",
    "- Lexicon-based tokenization on spaceless text has F1=0.79 (comparable fo Chinese F1=0.82), obtaied with \"hybrid\" (length-times-logweight-driven) parsing with results explainable by lack of word stress articulation and speech pauses (expectedly can be improved based on alternative tokenization-trees maximizing the weight across entire tree)\n",
    "- Precision of word discovery of Freedom-peak-based tokenizer is 0.99 (after correction for out-of-refernce-lexicon words, except single issue with question mark, not separated from the words), comparable with delimiter-based (1.0)\n",
    "\n",
    "| Language | Tokenizer | Tokenization F1 | Lexicon Discovery Precision |\n",
    "|---|---|---|---|\n",
    "| English | Freedom-based  | **0.99** | **0.99** (vs 1.0) |\n",
    "| English | Lexicon-based  | 0.99 | - |\n",
    "| English no spaces | Freedom-based | 0.42 | - |\n",
    "| English no spaces | Lexicon-based | 0.79 | - |\n",
    "| Russian | Freedom-based  | **1.0** | **1.0** (vs 1.0) |\n",
    "| Russian | Lexicon-based  | 0.94 | - |\n",
    "| Russian no spaces | Freedom-based | 0.26 | - |\n",
    "| Russian no spaces | Lexicon-based | 0.72 | - |\n",
    "| Chinese | Freedom-based  | **0.71** | **0.92** (vs 0.94) |\n",
    "| Chinese | Lexicon-based  | 0.83 | - |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec52562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "cwd = os.getcwd()\n",
    "project_path = cwd[:cwd.find('pygents')+7]\n",
    "if project_path not in sys.path: sys.path.append(project_path)\n",
    "os.chdir(project_path) \n",
    "\n",
    "#from importlib import reload  # Python 3.4+\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "#force reimport\n",
    "if 'pygents.util' in sys.modules:\n",
    "    del sys.modules['pygents.util']\n",
    "if 'pygents.text' in sys.modules:\n",
    "    del sys.modules['pygents.text']\n",
    "if 'pygents.plot' in sys.modules:\n",
    "    del sys.modules['pygents.plot']\n",
    "if 'pygents.token' in sys.modules:\n",
    "    del sys.modules['pygents.token']\n",
    "if 'pygents.token_plot' in sys.modules:\n",
    "    del sys.modules['pygents.token_plot']\n",
    "\n",
    "\n",
    "from pygents.token import *\n",
    "from pygents.text import *\n",
    "from pygents.util import *\n",
    "from pygents.plot import plot_bars, plot_dict, matrix_plot\n",
    "from pygents.token_plot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbd79e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What about medical insurance? As for my family...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For those who have insurance, according to the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Need to realize the importance of having insur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In fact, this phenomenon is indeed very common...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It is really necessary for this generation of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ant Insurance does not only offer car insuranc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>However, when buying a house, except for the d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>This kind of financial investment has certain ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>If your investment orientation is right, then ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>One more insurance means one more protection.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   en\n",
       "0   What about medical insurance? As for my family...\n",
       "1   For those who have insurance, according to the...\n",
       "2   Need to realize the importance of having insur...\n",
       "3   In fact, this phenomenon is indeed very common...\n",
       "4   It is really necessary for this generation of ...\n",
       "..                                                ...\n",
       "95  Ant Insurance does not only offer car insuranc...\n",
       "96  However, when buying a house, except for the d...\n",
       "97  This kind of financial investment has certain ...\n",
       "98  If your investment orientation is right, then ...\n",
       "99      One more insurance means one more protection.\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../../nlp/corpora/Chinese/'\n",
    "test_df = pd.read_csv(os.path.join(path,'magicdata/zh_en_ru_100/CORPUS_ZH_EN_RU.txt'),delimiter='\\t')\n",
    "test_texts = list(test_df['en'])\n",
    "print(len(test_texts))\n",
    "test_df[['en']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b02d53f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What about medical insurance? As for my family, either an adult or a child will buy insurance.\n",
      "For those who have insurance, according to the insurance contract, they will get a compensation of 300 thousand yuan.\n",
      "Need to realize the importance of having insurance.\n",
      "In fact, this phenomenon is indeed very common, for instance, for personal accident insurance, the more you buy, the more you insure.\n",
      "It is really necessary for this generation of parents to buy insurance.\n",
      "Well, right now, it's really advisable to buy insurance.\n",
      "A car must be bought in full, and a house can be bought with a loan.\n",
      "You can buy insurance, insurance is of course divided into many categories.\n",
      "Medical insurance is very important.\n",
      "It's the insurance company that pays this part of the money.\n",
      "Xianghubao, I don't know if you ever heard about it, it is insurance in Alipay.\n",
      "Buying a house is actually an investment.\n",
      "Have you ever learned about the training of Ping An Insurance?\n",
      "If it is deposited in the bank, what is the outcome of the compound interest?\n",
      "This sort of insurance is very sound in western countries.\n",
      "There are many industries that insurance may cover, you see it covers a very broad field.\n",
      "However, it is actually encouraging you to buy commercial insurance and life insurance.\n",
      "People who sell insurance all rely on their connections.\n",
      "Uh, social insurance is as well insurance, and your car insurance is, too, insurance.\n",
      "But the money from banks, if you take it out, is a kind of loan.\n",
      "Now it seems to be approaching a negative interest rate.\n",
      "I really have never tried to borrow money from a bank.\n",
      "He asks for no interest, so he simply lends the money and recovers it later.\n",
      "If you got bad credit information, he will not lend you money.\n",
      "Did he buy it through a loan or pay in full?\n",
      "Well, they sometimes have a lot of procedures when applying for a bank card.\n",
      "All kinds of banks, as well as five major banks.\n",
      "Are treasury bonds a type of securities?\n",
      "In fact, trading on the stock exchange itself is considered to have a relatively high-risk factor.\n",
      "Um, the profit would not be very high, it is supposed to be around the interest rate.\n",
      "Then it is used for real estate speculation. After a house has been appreciated, sell it and pay off the loan. Maybe one could earn hundreds of thousands of money.\n",
      "To get started with investing, the first step is to master the basics.\n",
      "Pricing methods for exchange rates include direct pricing and indirect pricing.\n",
      "Anyway, it is an investment behavior, an investment model, and an investment approach.\n",
      "What if I have spare money to buy an apartment for investment?\n",
      "become capital and invest in something else\n",
      "Having the pressure from a loan also means having the motivation to make money. I agree with that.\n",
      "If it is convenient to sign up for online banking?\n",
      "Where did you get the money you invested last time?\n",
      "The changes in bank policies prevent them from lending.\n",
      "An insurance company also provides financial products.\n",
      "It seems that our insurance company has a guaranteed interest rate of 2.8 percent.\n",
      "Many people are disgusted with insurance.\n",
      "They would rather keep the money in the bank for interest.\n",
      "It's great to start money management five years in advance because money management itself is very easy.\n",
      "It means you take a small part of your living expenses as savings.\n",
      "As for a bond fund, it offers a relatively stable profit, which is just like a fixed deposit but with more benefits.\n",
      "How many such acceptance drafts can theoretically be issued.\n",
      "It means that each of us should have our way to manage money, no matter in which way, no matter how much money we have.\n",
      "True, this loan will take more than ten years to pay off.\n",
      " It is fairly risky to start a business.\n",
      "Actually, it is considered a good way of investment, to wait for the appreciation.\n",
      "Actually, their financial management is also worth learning.\n",
      "if financial management is an essential part of our lives\n",
      "For example, I have tried many pieces of personal financial software before.\n",
      "It may probably just help you keep the money, but investment behaviors depend on yourself.\n",
      "I believe that good financial management can improve lives.\n",
      "If you want to buy a car, a house, or some other things, while you don't own enough money, you will be asking for a bank loan, right?\n",
      "A small problem doesn't equivalent to no problem, because your line of credit is not based on how many credit cards you have.\n",
      "for example, the broker-dealer qualification certificate, the banker certificate\n",
      "Actually, I think buying insurance is also beneficial. You can regard it as saving money.\n",
      "What is a claim, what is not?\n",
      "Make a plan, and then choose appropriate commercial insurance.\n",
      "With a tax of approximately 500 thousand yuan, a down payment of 500 thousand yuan, you have to repay a loan for 20 years.\n",
      "And this insurance has very broad coverage.\n",
      "One aged up to eighty and down to eight can be insured.\n",
      "Insurance has been becoming more formal and more standardized.\n",
      "So, now the penetration rate of having insurance is basically over 80%.\n",
      "Because in our country, insurance started relatively late in comparison with Western countries.\n",
      "The one directly bound to the bank card, either a credit card or a debit card can be used.\n",
      "When you apply for insurance, you can't have these infectious diseases.\n",
      "Now the reimbursement rate has been raised, plus commercial insurance as a supplement.\n",
      "that kind with an interest rate reaches 150% or more\n",
      "From a legal point of view, insurance is another contractual action.\n",
      "I slowly realized that it is indeed necessary to get insurance, which is a sort of security for myself and my children.\n",
      "Maternity insurance and basic medical insurance are combined.\n",
      "An insurance bundle is a kind of tie-in sale, in fact, you can make a free match.\n",
      "However, since it is difficult to estimate the value of human life and body, life insurance does not apply this principle.\n",
      "After an accident, the compensation the insured received shall be shared by the insurance company and the insured.\n",
      "The purpose of establishing an insurance system is to deal with specific accidents.\n",
      "Not in the insurable range, so commercial insurance institutions generally do not underwrite this.\n",
      "For example, if you met with a traffic accident, someone was hit, and you, therefore, need to pay a certain amount.\n",
      "For example, a very simple example, such as an earthquake or a fire occurred, do you believe the insurance company will compensate you?\n",
      "Commercial insurance is profitable, and it is a commercial activity.\n",
      "Legally, insuring is a contractual action.\n",
      "Through signing an insurance contract, the rights and obligations of both parties are clarified.\n",
      "The insured pays premiums to obtain compensation within the scope of an insurance contract.\n",
      "The insurance company will not pay you compensation in any amount.\n",
      "Social insurance means the five social insurance and the housing provident fund which are mandatory.\n",
      "through the change of the benchmark interest rate\n",
      "Well, issue loans to some companies, like real estate companies.\n",
      "Installments consumption saved 30% of Apple's market share.\n",
      "Um, how much will you pay for the premium for a year?\n",
      "What kind of insurance does your car have?\n",
      "But the insurance company will settle the claim.\n",
      "Ant Insurance does not only offer car insurance, but I have also seen a variety of insurance.\n",
      "However, when buying a house, except for the down payment, the monthly mortgage is equivalent to rent.\n",
      "This kind of financial investment has certain risks for personal property.\n",
      "If your investment orientation is right, then it has a far greater advantage than deposits.\n",
      "One more insurance means one more protection.\n"
     ]
    }
   ],
   "source": [
    "for text in test_texts:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65519d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del_tokenizer = DelimiterTokenizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "204cd1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97565\n",
      "('the', 53097401)\n",
      "97565\n",
      "53097401\n",
      "34\n",
      "97599\n"
     ]
    }
   ],
   "source": [
    "#get raw lexicon list\n",
    "en_lex = list(pd.read_csv(\"https://raw.githubusercontent.com/aigents/aigents-java/master/lexicon_english.txt\",sep='\\t',header=None,na_filter=False).to_records(index=False))\n",
    "print(len(en_lex))\n",
    "\n",
    "#debug raw lexicon\n",
    "print(max(en_lex,key=lambda item:item[1]))\n",
    "en_lex_dict = weightedlist2dict(en_lex,lower=False) # no case-insensitive merge\n",
    "print(len(en_lex_dict))\n",
    "\n",
    "# merge and get top weight\n",
    "en_lex_dict = weightedlist2dict(en_lex,lower=True) # with case-insensitive merge\n",
    "top_weight = max([en_lex_dict[key] for key in en_lex_dict],key=lambda item:item)\n",
    "print(top_weight)\n",
    "\n",
    "# add delimiters to the list\n",
    "en_lex_delimited = en_lex + [(i, top_weight) for i in list(delimiters)]\n",
    "print(len(delimiters))\n",
    "print(len(en_lex_delimited)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0184554c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 97565\n",
      "0.94\n",
      "0.48\n",
      "0.93\n",
      "\n",
      "1e-05 40382\n",
      "0.94\n",
      "0.48\n",
      "0.93\n",
      "\n",
      "0.0001 10122\n",
      "0.92\n",
      "0.48\n",
      "0.92\n",
      "\n",
      "0.001 1570\n",
      "0.71\n",
      "0.48\n",
      "0.71\n",
      "\n",
      "0.01 118\n",
      "0.37\n",
      "0.31\n",
      "0.37\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# no delimiters\n",
    "filter_thresholds = [0,0.00001,0.0001,0.001,0.01]\n",
    "for t in filter_thresholds:\n",
    "    lex = listofpairs_compress_with_loss(en_lex,t) if t > 0 else en_lex\n",
    "    en_lex0_tokenizer = LexiconIndexedTokenizer(lexicon=lex,sortmode=0,cased=True)\n",
    "    en_lex1_tokenizer = LexiconIndexedTokenizer(lexicon=lex,sortmode=1,cased=True)\n",
    "    en_lex2_tokenizer = LexiconIndexedTokenizer(lexicon=lex,sortmode=2,cased=True)\n",
    "    print(t,en_lex0_tokenizer.count_params())\n",
    "    print(evaluate_tokenizer_f1(test_texts,del_tokenizer,en_lex0_tokenizer,debug=False))#sort by len\n",
    "    print(evaluate_tokenizer_f1(test_texts,del_tokenizer,en_lex1_tokenizer,debug=False))#sort by freq\n",
    "    print(evaluate_tokenizer_f1(test_texts,del_tokenizer,en_lex2_tokenizer,debug=False))#sort by len and freq\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b97d7e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 97599\n",
      "0.99\n",
      "0.52\n",
      "0.98\n",
      "\n",
      "1e-05 40416\n",
      "0.99\n",
      "0.52\n",
      "0.98\n",
      "\n",
      "0.0001 10156\n",
      "0.97\n",
      "0.52\n",
      "0.97\n",
      "\n",
      "0.001 1604\n",
      "0.75\n",
      "0.52\n",
      "0.75\n",
      "\n",
      "0.01 152\n",
      "0.58\n",
      "0.54\n",
      "0.58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with delimiters\n",
    "filter_thresholds = [0,0.00001,0.0001,0.001,0.01]\n",
    "for t in filter_thresholds:\n",
    "    lex = listofpairs_compress_with_loss(en_lex_delimited,t) if t > 0 else en_lex_delimited\n",
    "    en_lex0_tokenizer = LexiconIndexedTokenizer(lexicon=lex,sortmode=0,cased=True)\n",
    "    en_lex1_tokenizer = LexiconIndexedTokenizer(lexicon=lex,sortmode=1,cased=True)\n",
    "    en_lex2_tokenizer = LexiconIndexedTokenizer(lexicon=lex,sortmode=2,cased=True)\n",
    "    print(t,en_lex0_tokenizer.count_params())\n",
    "    print(evaluate_tokenizer_f1(test_texts,del_tokenizer,en_lex0_tokenizer,debug=False))#sort by len\n",
    "    print(evaluate_tokenizer_f1(test_texts,del_tokenizer,en_lex1_tokenizer,debug=False))#sort by freq\n",
    "    print(evaluate_tokenizer_f1(test_texts,del_tokenizer,en_lex2_tokenizer,debug=False))#sort by len and freq\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b76847f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Well', ',', ' ', 'right', ' ', 'now', ',', ' ', \"it's\", ' ', 'really', ' ', 'advisable', ' ', 'to', ' ', 'buy', ' ', 'insurance', '.']\n",
      "['Well', ',', ' ', 'right', ' ', 'now', ',', ' ', 'it', \"'\", 's', ' ', 'really', ' ', 'advisable', ' ', 'to', ' ', 'buy', ' ', 'insurance', '.']\n",
      "0.9\n",
      "[\"It's\", ' ', 'the', ' ', 'insurance', ' ', 'company', ' ', 'that', ' ', 'pays', ' ', 'this', ' ', 'part', ' ', 'of', ' ', 'the', ' ', 'money', '.']\n",
      "['It', \"'\", 's', ' ', 'the', ' ', 'insurance', ' ', 'company', ' ', 'that', ' ', 'pays', ' ', 'this', ' ', 'part', ' ', 'of', ' ', 'the', ' ', 'money', '.']\n",
      "0.91\n",
      "['Xianghubao', ',', ' ', 'I', ' ', \"don't\", ' ', 'know', ' ', 'if', ' ', 'you', ' ', 'ever', ' ', 'heard', ' ', 'about', ' ', 'it', ',', ' ', 'it', ' ', 'is', ' ', 'insurance', ' ', 'in', ' ', 'Alipay', '.']\n",
      "['Xiang', 'hub', 'ao', ',', ' ', 'I', ' ', 'don', \"'\", 't', ' ', 'know', ' ', 'if', ' ', 'you', ' ', 'ever', ' ', 'heard', ' ', 'about', ' ', 'it', ',', ' ', 'it', ' ', 'is', ' ', 'insurance', ' ', 'in', ' ', 'Ali', 'pay', '.']\n",
      "0.84\n",
      "['In', ' ', 'fact', ',', ' ', 'trading', ' ', 'on', ' ', 'the', ' ', 'stock', ' ', 'exchange', ' ', 'itself', ' ', 'is', ' ', 'considered', ' ', 'to', ' ', 'have', ' ', 'a', ' ', 'relatively', ' ', 'high-risk', ' ', 'factor', '.']\n",
      "['In', ' ', 'fact', ',', ' ', 'trading', ' ', 'on', ' ', 'the', ' ', 'stock', ' ', 'exchange', ' ', 'itself', ' ', 'is', ' ', 'considered', ' ', 'to', ' ', 'have', ' ', 'a', ' ', 'relatively', ' ', 'high', '-', 'risk', ' ', 'factor', '.']\n",
      "0.94\n",
      "['It', ' ', 'seems', ' ', 'that', ' ', 'our', ' ', 'insurance', ' ', 'company', ' ', 'has', ' ', 'a', ' ', 'guaranteed', ' ', 'interest', ' ', 'rate', ' ', 'of', ' ', '2.8', ' ', 'percent', '.']\n",
      "['It', ' ', 'seems', ' ', 'that', ' ', 'our', ' ', 'insurance', ' ', 'company', ' ', 'has', ' ', 'a', ' ', 'guaranteed', ' ', 'interest', ' ', 'rate', ' ', 'of', ' ', '2', '.', '8', ' ', 'percent', '.']\n",
      "0.93\n",
      "[\"It's\", ' ', 'great', ' ', 'to', ' ', 'start', ' ', 'money', ' ', 'management', ' ', 'five', ' ', 'years', ' ', 'in', ' ', 'advance', ' ', 'because', ' ', 'money', ' ', 'management', ' ', 'itself', ' ', 'is', ' ', 'very', ' ', 'easy', '.']\n",
      "['It', \"'\", 's', ' ', 'great', ' ', 'to', ' ', 'start', ' ', 'money', ' ', 'management', ' ', 'five', ' ', 'years', ' ', 'in', ' ', 'advance', ' ', 'because', ' ', 'money', ' ', 'management', ' ', 'itself', ' ', 'is', ' ', 'very', ' ', 'easy', '.']\n",
      "0.94\n",
      "['It', ' ', 'is', ' ', 'fairly', ' ', 'risky', ' ', 'to', ' ', 'start', ' ', 'a', ' ', 'business', '.']\n",
      "[' ', 'It', ' ', 'is', ' ', 'fairly', ' ', 'risky', ' ', 'to', ' ', 'start', ' ', 'a', ' ', 'business', '.']\n",
      "0.97\n",
      "['If', ' ', 'you', ' ', 'want', ' ', 'to', ' ', 'buy', ' ', 'a', ' ', 'car', ',', ' ', 'a', ' ', 'house', ',', ' ', 'or', ' ', 'some', ' ', 'other', ' ', 'things', ',', ' ', 'while', ' ', 'you', ' ', \"don't\", ' ', 'own', ' ', 'enough', ' ', 'money', ',', ' ', 'you', ' ', 'will', ' ', 'be', ' ', 'asking', ' ', 'for', ' ', 'a', ' ', 'bank', ' ', 'loan', ',', ' ', 'right', '?']\n",
      "['If', ' ', 'you', ' ', 'want', ' ', 'to', ' ', 'buy', ' ', 'a', ' ', 'car', ',', ' ', 'a', ' ', 'house', ',', ' ', 'or', ' ', 'some', ' ', 'other', ' ', 'things', ',', ' ', 'while', ' ', 'you', ' ', 'don', \"'\", 't', ' ', 'own', ' ', 'enough', ' ', 'money', ',', ' ', 'you', ' ', 'will', ' ', 'be', ' ', 'asking', ' ', 'for', ' ', 'a', ' ', 'bank', ' ', 'loan', ',', ' ', 'right', '?']\n",
      "0.97\n",
      "['A', ' ', 'small', ' ', 'problem', ' ', \"doesn't\", ' ', 'equivalent', ' ', 'to', ' ', 'no', ' ', 'problem', ',', ' ', 'because', ' ', 'your', ' ', 'line', ' ', 'of', ' ', 'credit', ' ', 'is', ' ', 'not', ' ', 'based', ' ', 'on', ' ', 'how', ' ', 'many', ' ', 'credit', ' ', 'cards', ' ', 'you', ' ', 'have', '.']\n",
      "['A', ' ', 'small', ' ', 'problem', ' ', 'doesn', \"'\", 't', ' ', 'equivalent', ' ', 'to', ' ', 'no', ' ', 'problem', ',', ' ', 'because', ' ', 'your', ' ', 'line', ' ', 'of', ' ', 'credit', ' ', 'is', ' ', 'not', ' ', 'based', ' ', 'on', ' ', 'how', ' ', 'many', ' ', 'credit', ' ', 'cards', ' ', 'you', ' ', 'have', '.']\n",
      "0.96\n",
      "['for', ' ', 'example', ',', ' ', 'the', ' ', 'broker-dealer', ' ', 'qualification', ' ', 'certificate', ',', ' ', 'the', ' ', 'banker', ' ', 'certificate']\n",
      "['for', ' ', 'example', ',', ' ', 'the', ' ', 'broker', '-', 'dealer', ' ', 'qualification', ' ', 'certificate', ',', ' ', 'the', ' ', 'banker', ' ', 'certificate']\n",
      "0.9\n",
      "['When', ' ', 'you', ' ', 'apply', ' ', 'for', ' ', 'insurance', ',', ' ', 'you', ' ', \"can't\", ' ', 'have', ' ', 'these', ' ', 'infectious', ' ', 'diseases', '.']\n",
      "['When', ' ', 'you', ' ', 'apply', ' ', 'for', ' ', 'insurance', ',', ' ', 'you', ' ', 'can', \"'\", 't', ' ', 'have', ' ', 'these', ' ', 'infectious', ' ', 'diseases', '.']\n",
      "0.92\n",
      "['An', ' ', 'insurance', ' ', 'bundle', ' ', 'is', ' ', 'a', ' ', 'kind', ' ', 'of', ' ', 'tie-in', ' ', 'sale', ',', ' ', 'in', ' ', 'fact', ',', ' ', 'you', ' ', 'can', ' ', 'make', ' ', 'a', ' ', 'free', ' ', 'match', '.']\n",
      "['An', ' ', 'insurance', ' ', 'bundle', ' ', 'is', ' ', 'a', ' ', 'kind', ' ', 'of', ' ', 'tie', '-', 'in', ' ', 'sale', ',', ' ', 'in', ' ', 'fact', ',', ' ', 'you', ' ', 'can', ' ', 'make', ' ', 'a', ' ', 'free', ' ', 'match', '.']\n",
      "0.95\n",
      "['Installments', ' ', 'consumption', ' ', 'saved', ' ', '30%', ' ', 'of', ' ', \"Apple's\", ' ', 'market', ' ', 'share', '.']\n",
      "['Installments', ' ', 'consumption', ' ', 'saved', ' ', '30%', ' ', 'of', ' ', 'Apple', \"'\", 's', ' ', 'market', ' ', 'share', '.']\n",
      "0.88\n"
     ]
    }
   ],
   "source": [
    "en_lex0_tokenizer = LexiconIndexedTokenizer(lexicon=en_lex_delimited,sortmode=0,cased=True)\n",
    "for text in test_texts:\n",
    "    expected = del_tokenizer.tokenize(text)\n",
    "    actual = en_lex0_tokenizer.tokenize(text)\n",
    "    f1 = calc_f1(expected,actual)\n",
    "    if f1 < 1:\n",
    "        print(expected)\n",
    "        print(actual)\n",
    "        print(round(f1,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9569ccf",
   "metadata": {},
   "source": [
    "## Explore validity of the discovered lexicon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3aecb3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_lex_delimited_dict = weightedlist2dict(en_lex_delimited,lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb86af46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use SOTA - I\n",
    "base = FreedomTokenizer(name='data/models/brown_nolines_chars_7a',max_n=7,mode='chars',debug=False)\n",
    "model_compress_with_loss(base.model,0.0001)\n",
    "test_tokenizer = FreedomBasedTokenizer(base,'ddf-','ddf+')\n",
    "test_tokenizer.set_options(nlist = [1], threshold=0.4) # expected F1=0.99\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c829576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99\n"
     ]
    }
   ],
   "source": [
    "expected = {}\n",
    "actual = {}\n",
    "f1 = evaluate_tokenizer_f1(test_texts,del_tokenizer,test_tokenizer,expected_collector=expected,actual_collector=actual)\n",
    "print(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10a6800f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total relevant false precision\n",
      "2698 2677 21 0.992216456634544 1.0\n",
      "2694 2662 32 0.9881217520415738 0.9955456570155902\n"
     ]
    }
   ],
   "source": [
    "#collected tokens\n",
    "\n",
    "print('total relevant false precision')\n",
    "\n",
    "expected_count = sum([expected[key] for key in expected])\n",
    "relevant_count = sum([expected[key] for key in expected if key.lower() in en_lex_delimited_dict])\n",
    "irrelevant_count = sum([expected[key] for key in expected if not key.lower() in en_lex_delimited_dict])\n",
    "print(expected_count,relevant_count,irrelevant_count,relevant_count/expected_count,(relevant_count+21)/expected_count)\n",
    "\n",
    "actual_count = sum([actual[key] for key in actual])\n",
    "relevant_count = sum([actual[key] for key in actual if key.lower() in en_lex_delimited_dict])\n",
    "irrelevant_count = sum([actual[key] for key in actual if not key.lower() in en_lex_delimited_dict])\n",
    "print(actual_count,relevant_count,irrelevant_count,relevant_count/actual_count,(relevant_count+20)/actual_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b8e613d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"It's\", 2),\n",
       " (\"don't\", 2),\n",
       " ('500', 2),\n",
       " ('300', 1),\n",
       " (\"it's\", 1),\n",
       " ('Xianghubao', 1),\n",
       " ('Alipay', 1),\n",
       " ('high-risk', 1),\n",
       " ('2.8', 1),\n",
       " (\"doesn't\", 1),\n",
       " ('broker-dealer', 1),\n",
       " ('20', 1),\n",
       " ('80%', 1),\n",
       " (\"can't\", 1),\n",
       " ('150%', 1),\n",
       " ('tie-in', 1),\n",
       " ('30%', 1),\n",
       " (\"Apple's\", 1)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#delimiter-based tokenizer\n",
    "misses = sorted([(key,expected[key]) for key in expected if not key.lower() in en_lex_delimited_dict],key = lambda x: x[1],reverse=True)\n",
    "misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22e5d5a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"It's\", 2),\n",
       " (\"don't\", 2),\n",
       " ('500', 2),\n",
       " ('insurance?', 1),\n",
       " ('300', 1),\n",
       " (\"it's\", 1),\n",
       " ('Xianghubao', 1),\n",
       " ('Alipay', 1),\n",
       " ('Insurance?', 1),\n",
       " ('interest?', 1),\n",
       " ('full?', 1),\n",
       " ('securities?', 1),\n",
       " ('investment?', 1),\n",
       " ('banking?', 1),\n",
       " ('time?', 1),\n",
       " ('2', 1),\n",
       " ('.8', 1),\n",
       " ('right?', 1),\n",
       " (\"doesn't\", 1),\n",
       " ('not?', 1),\n",
       " ('20', 1),\n",
       " ('80%', 1),\n",
       " (\"can't\", 1),\n",
       " ('150%', 1),\n",
       " ('you?', 1),\n",
       " ('30%', 1),\n",
       " (\"'s\", 1),\n",
       " ('year?', 1),\n",
       " ('have?', 1)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#freedom-based tokenizer\n",
    "misses = sorted([(key,actual[key]) for key in actual if not key.lower() in en_lex_delimited_dict],key = lambda x: x[1],reverse=True)\n",
    "misses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55717cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use SOTA - II\n",
    "base = FreedomTokenizer(name='data/models/gutenberg_brown_chars_7a',max_n=7,mode='chars',debug=False)\n",
    "model_compress_with_loss(base.model,0.0001)\n",
    "test_tokenizer = FreedomBasedTokenizer(base,'ddf-','ddf+')\n",
    "test_tokenizer.set_options(nlist = [1], threshold=0.4) # expected F1=0.99\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b53967c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99\n"
     ]
    }
   ],
   "source": [
    "expected = {}\n",
    "actual = {}\n",
    "f1 = evaluate_tokenizer_f1(test_texts,del_tokenizer,test_tokenizer,expected_collector=expected,actual_collector=actual)\n",
    "print(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be0b5efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total relevant false precision\n",
      "2698 2677 21 0.992216456634544 1.0\n",
      "2694 2662 32 0.9881217520415738 0.9955456570155902\n"
     ]
    }
   ],
   "source": [
    "#collected tokens\n",
    "\n",
    "print('total relevant false precision')\n",
    "\n",
    "expected_count = sum([expected[key] for key in expected])\n",
    "relevant_count = sum([expected[key] for key in expected if key.lower() in en_lex_delimited_dict])\n",
    "irrelevant_count = sum([expected[key] for key in expected if not key.lower() in en_lex_delimited_dict])\n",
    "print(expected_count,relevant_count,irrelevant_count,relevant_count/expected_count,(relevant_count+21)/expected_count)\n",
    "\n",
    "actual_count = sum([actual[key] for key in actual])\n",
    "relevant_count = sum([actual[key] for key in actual if key.lower() in en_lex_delimited_dict])\n",
    "irrelevant_count = sum([actual[key] for key in actual if not key.lower() in en_lex_delimited_dict])\n",
    "print(actual_count,relevant_count,irrelevant_count,relevant_count/actual_count,(relevant_count+20)/actual_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a267b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"It's\", 2),\n",
       " (\"don't\", 2),\n",
       " ('500', 2),\n",
       " ('insurance?', 1),\n",
       " ('300', 1),\n",
       " (\"it's\", 1),\n",
       " ('Xianghubao', 1),\n",
       " ('Alipay', 1),\n",
       " ('Insurance?', 1),\n",
       " ('interest?', 1),\n",
       " ('full?', 1),\n",
       " ('securities?', 1),\n",
       " ('investment?', 1),\n",
       " ('banking?', 1),\n",
       " ('time?', 1),\n",
       " ('2', 1),\n",
       " ('.8', 1),\n",
       " ('right?', 1),\n",
       " (\"doesn't\", 1),\n",
       " ('not?', 1),\n",
       " ('20', 1),\n",
       " ('80%', 1),\n",
       " (\"can't\", 1),\n",
       " ('150%', 1),\n",
       " ('you?', 1),\n",
       " ('30%', 1),\n",
       " (\"'s\", 1),\n",
       " ('year?', 1),\n",
       " ('have?', 1)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#freedom-based tokenizer\n",
    "misses = sorted([(key,actual[key]) for key in actual if not key.lower() in en_lex_delimited_dict],key = lambda x: x[1],reverse=True)\n",
    "misses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b153b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
