{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a257e2ca",
   "metadata": {},
   "source": [
    "# Russian Tokenization Model - Experiments - PROGRESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb56b8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "cwd = os.getcwd()\n",
    "project_path = cwd[:cwd.find('pygents')+7]\n",
    "if project_path not in sys.path: sys.path.append(project_path)\n",
    "os.chdir(project_path) \n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "#force reimport\n",
    "if 'pygents.util' in sys.modules:\n",
    "    del sys.modules['pygents.util']\n",
    "if 'pygents.text' in sys.modules:\n",
    "    del sys.modules['pygents.text']\n",
    "if 'pygents.plot' in sys.modules:\n",
    "    del sys.modules['pygents.plot']\n",
    "if 'pygents.token' in sys.modules:\n",
    "    del sys.modules['pygents.token']\n",
    "\n",
    "from pygents.util import * \n",
    "from pygents.text import * \n",
    "from pygents.plot import * \n",
    "from pygents.token import * \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93b302ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://nlpub.ru/%D0%A0%D0%B5%D1%81%D1%83%D1%80%D1%81%D1%8B - Inventory\n",
    "\n",
    "# http://study.mokoron.com/ - Twitter, need to extract froom SQL\n",
    "# https://linguatools.org/tools/corpora/wikipedia-monolingual-corpora/ - Wiki, need to extract from XML\n",
    "\n",
    "# RusAge\n",
    "# https://www.kaggle.com/datasets/oldaandozerskaya/fiction-corpus-for-agebased-text-classification - just txt books\n",
    "\n",
    "path = '../../nlp/corpora/Russian/rusage/archive/previews'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1ae4f6",
   "metadata": {},
   "source": [
    "## Load and explore full models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "963b273b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 children_2522.txt\n",
      "200 children_2053.txt\n",
      "300 children_481.txt\n",
      "400 adults_1893.txt\n",
      "500 adults_1267.txt\n",
      "600 adults_1662.txt\n",
      "700 adults_1464.txt\n",
      "800 children_2281.txt\n",
      "900 children_1789.txt\n",
      "1000 children_487.txt\n",
      "1100 adults_2350.txt\n",
      "1200 adults_1274.txt\n",
      "1300 children_2334.txt\n",
      "1400 children_2421.txt\n",
      "1500 adults_2083.txt\n",
      "1600 children_757.txt\n",
      "1700 children_2178.txt\n",
      "1800 adults_2282.txt\n",
      "1900 adults_539.txt\n",
      "2000 children_146.txt\n",
      "2100 children_1112.txt\n",
      "2200 children_1502.txt\n",
      "2300 adults_1957.txt\n",
      "2400 children_431.txt\n",
      "2500 children_2578.txt\n",
      "2600 children_1528.txt\n",
      "2700 children_168.txt\n",
      "2800 adults_863.txt\n",
      "2900 children_207.txt\n",
      "3000 adults_1780.txt\n",
      "3100 children_1.txt\n",
      "3200 children_748.txt\n",
      "3300 children_588.txt\n",
      "3400 children_1123.txt\n",
      "3500 children_605.txt\n",
      "3600 adults_1585.txt\n",
      "3700 children_1720.txt\n",
      "3800 adults_1394.txt\n",
      "3900 adults_912.txt\n",
      "4000 children_571.txt\n",
      "4100 children_2438.txt\n",
      "4200 adults_182.txt\n",
      "4300 adults_2764.txt\n",
      "4400 children_2489.txt\n",
      "4500 adults_368.txt\n",
      "4600 adults_2571.txt\n",
      "4700 adults_1737.txt\n",
      "4800 adults_1469.txt\n",
      "4900 adults_147.txt\n",
      "5000 adults_2763.txt\n",
      "5100 adults_152.txt\n",
      "5200 adults_1308.txt\n",
      "5300 children_1225.txt\n",
      "5400 adults_780.txt\n",
      "28998065\n"
     ]
    }
   ],
   "source": [
    "#TODO function\n",
    "if False:\n",
    "    rusage_chars = FreedomTokenizer(max_n=5,mode='chars',debug=False)\n",
    "    #rusage_grams = FreedomTokenizer(max_n=5,mode='grams',debug=False)\n",
    "\n",
    "    path = '../../nlp/corpora/Russian/rusage/archive/previews'\n",
    "    onlyfiles = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    cnt = 0\n",
    "    for file in onlyfiles:\n",
    "        with open(join(path, file),errors='ignore') as f:\n",
    "            lines = f.readlines()\n",
    "            cnt += 1\n",
    "            if (cnt % 100) == 0:\n",
    "                print(cnt,file)\n",
    "            rusage_chars.train(lines)\n",
    "            #rusage_grams.train(lines)\n",
    "\n",
    "    rusage_chars.store('data/models/rusage_chars_5a')\n",
    "    #rusage_grams.store('data/models/rusage_grams_7a')\n",
    "\n",
    "    print(rusage_chars.count_params())\n",
    "#28,998,065\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f7b76e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 children_2522.txt\n",
      "200 children_2053.txt\n",
      "300 children_481.txt\n",
      "400 adults_1893.txt\n",
      "500 adults_1267.txt\n",
      "600 adults_1662.txt\n",
      "700 adults_1464.txt\n",
      "800 children_2281.txt\n",
      "900 children_1789.txt\n",
      "1000 children_487.txt\n",
      "1100 adults_2350.txt\n",
      "1200 adults_1274.txt\n",
      "1300 children_2334.txt\n",
      "1400 children_2421.txt\n",
      "1500 adults_2083.txt\n",
      "1600 children_757.txt\n",
      "1700 children_2178.txt\n",
      "1800 adults_2282.txt\n",
      "1900 adults_539.txt\n",
      "2000 children_146.txt\n",
      "2100 children_1112.txt\n",
      "2200 children_1502.txt\n",
      "2300 adults_1957.txt\n",
      "2400 children_431.txt\n",
      "2500 children_2578.txt\n",
      "2600 children_1528.txt\n",
      "2700 children_168.txt\n",
      "2800 adults_863.txt\n",
      "2900 children_207.txt\n",
      "3000 adults_1780.txt\n",
      "3100 children_1.txt\n",
      "3200 children_748.txt\n",
      "3300 children_588.txt\n",
      "3400 children_1123.txt\n",
      "3500 children_605.txt\n",
      "3600 adults_1585.txt\n",
      "3700 children_1720.txt\n",
      "3800 adults_1394.txt\n",
      "3900 adults_912.txt\n",
      "4000 children_571.txt\n",
      "4100 children_2438.txt\n",
      "4200 adults_182.txt\n",
      "4300 adults_2764.txt\n",
      "4400 children_2489.txt\n",
      "4500 adults_368.txt\n",
      "4600 adults_2571.txt\n",
      "4700 adults_1737.txt\n",
      "4800 adults_1469.txt\n",
      "4900 adults_147.txt\n",
      "5000 adults_2763.txt\n",
      "5100 adults_152.txt\n",
      "5200 adults_1308.txt\n",
      "5300 children_1225.txt\n",
      "5400 adults_780.txt\n",
      "207808799\n"
     ]
    }
   ],
   "source": [
    "#TODO function\n",
    "if True:\n",
    "    rusage_chars_7 = FreedomTokenizer(max_n=7,mode='chars',debug=False)\n",
    "    #rusage_grams = FreedomTokenizer(max_n=5,mode='grams',debug=False)\n",
    "\n",
    "    path = '../../nlp/corpora/Russian/rusage/archive/previews'\n",
    "    onlyfiles = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    cnt = 0\n",
    "    for file in onlyfiles:\n",
    "        with open(join(path, file),errors='ignore') as f:\n",
    "            lines = f.readlines()\n",
    "            cnt += 1\n",
    "            if (cnt % 100) == 0:\n",
    "                print(cnt,file)\n",
    "            rusage_chars_7.train(lines)\n",
    "            #rusage_grams.train(lines)\n",
    "\n",
    "    rusage_chars_7.store('data/models/rusage_chars_7a')\n",
    "    #rusage_grams.store('data/models/rusage_grams_7a')\n",
    "\n",
    "    print(rusage_chars_7.count_params())\n",
    "#207,808,799\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b309c0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "del rusage_chars_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a276656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_folder(self,folder_path,model_path,name=None,debug = False,odd=None):\n",
    "    #TODO recursion, if specified\n",
    "    onlyfiles = [f for f in listdir(folder_path) if isfile(join(folder_path, f))]\n",
    "    cnt = 0\n",
    "    for file in onlyfiles:\n",
    "        with open(join(path, file),errors='ignore') as f:\n",
    "            lines = f.readlines()\n",
    "            cnt += 1\n",
    "            if debug and (cnt % 100) == 0:\n",
    "                print(cnt,file)\n",
    "            if not odd is None:\n",
    "                if odd and (cnt % 2) == 0:\n",
    "                    continue\n",
    "                if (not odd) and (cnt % 2) != 0:\n",
    "                    continue\n",
    "            self.train(lines)\n",
    "    self.store(model_path)\n",
    "    if debug:\n",
    "        print(self.count_params())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ea73e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    rusage_test_chars_7 = FreedomTokenizer(max_n=7,mode='chars',debug=False)\n",
    "    train_folder(rusage_test_chars_7,'../../nlp/corpora/Russian/rusage/archive/test','data/models/rusage_test_chars_7a')\n",
    "#75,193,666 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5ba1221",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    rusage_test1_chars_7 = FreedomTokenizer(max_n=7,mode='chars',debug=False)\n",
    "    train_folder(rusage_test1_chars_7,'../../nlp/corpora/Russian/rusage/archive/test','data/models/rusage_test1_chars_7',odd=True)\n",
    "\n",
    "    rusage_test2_chars_7 = FreedomTokenizer(max_n=7,mode='chars',debug=False)\n",
    "    train_folder(rusage_test2_chars_7,'../../nlp/corpora/Russian/rusage/archive/test','data/models/rusage_test2_chars_7',odd=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdaae25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4523e176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0905b7fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497d0c3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
