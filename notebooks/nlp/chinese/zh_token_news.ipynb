{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67240a3d",
   "metadata": {},
   "source": [
    "# Chinese (Simplified) Tokenization Model - Experiments - TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfa4a19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "cwd = os.getcwd()\n",
    "project_path = cwd[:cwd.find('pygents')+7]\n",
    "if project_path not in sys.path: sys.path.append(project_path)\n",
    "os.chdir(project_path) \n",
    "\n",
    "from importlib import reload  # Python 3.4+\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "#force reimport\n",
    "if 'pygents.util' in sys.modules:\n",
    "    del sys.modules['pygents.util']\n",
    "if 'pygents.text' in sys.modules:\n",
    "    del sys.modules['pygents.text']\n",
    "if 'pygents.plot' in sys.modules:\n",
    "    del sys.modules['pygents.plot']\n",
    "if 'pygents.token' in sys.modules:\n",
    "    del sys.modules['pygents.token']\n",
    "\n",
    "from pygents.util import * \n",
    "from pygents.text import * \n",
    "from pygents.plot import * \n",
    "from pygents.token import * \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a886e80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.vengaglobal.com/blog/simplified-traditional-chinese-mandarin-cantonese/\n",
    "\n",
    "# Target Market  Written      Spoken\n",
    "# -------------------------------------\n",
    "# China          Simplified   Mandarin\n",
    "# Singapore      Simplified   Mandarin\n",
    "# Taiwan         Traditional  Mandarin\n",
    "# Hong Kong      Traditional  Cantonese\n",
    "\n",
    "# Lexicon:\n",
    "# http://www.chineselexicaldatabase.com/download.php - used below\n",
    "# Sun, C. C., Hendrix, P., Ma, J.Q. & Baayen, R. H. (2018). Chinese Lexical Database (CLD): A large-scale lexical database for simplified Mandarin Chinese. Behavior Research Methods, https://doi.org/10.3758/s13428-018-1038-3.\n",
    "\n",
    "# Corpora:\n",
    "# https://www.openslr.org/38/ - test-audio corpus, not relevant\n",
    "# https://github.com/CLUEbenchmark/CLUECorpus2020/ - email request sent\n",
    "# https://github.com/brightmart/nlp_chinese_corpus - nearly same as above downloaded, used further\n",
    "\n",
    "# TODO:\n",
    "# https://metatext.io/datasets/nlp-chinese-corpus - paper with word segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0942142",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../nlp/corpora/Chinese/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "523eaa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zh_clue_json2text(path,filename):\n",
    "    with open(os.path.join(path,filename+'.json')) as file:\n",
    "        with open(os.path.join(path,filename+'.txt'), 'w') as fout:\n",
    "            while True:\n",
    "                line = file.readline()\n",
    "                if not line:\n",
    "                    break\n",
    "                j = json.loads(line)\n",
    "                #print('title',j['title'])\n",
    "                #print('desc',j['desc'])\n",
    "                #print('content',j['content'])\n",
    "                fout.write(j['title'])\n",
    "                fout.write('\\n')    \n",
    "                fout.write(j['desc'])\n",
    "                fout.write('\\n')    \n",
    "                fout.write(j['content'])\n",
    "                fout.write('\\n')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dd8f704",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do this once!\n",
    "#zh_clue_json2text(path,'clue/new2016zh/news2016zh_valid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5a4778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do this once!\n",
    "#zh_clue_json2text(path,'clue/new2016zh/news2016zh_train')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2989ca52",
   "metadata": {},
   "source": [
    "## Load and explore full models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c22921a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lb/1m7gbdp17h578qq48pbbtxf40000gn/T/ipykernel_91711/3614049384.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#zh_valid_grams = FreedomTokenizer(max_n=3,mode='grams',debug=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'clue/new2016zh/news2016zh_valid.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mcnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'path' is not defined"
     ]
    }
   ],
   "source": [
    "zh_valid_chars = FreedomTokenizer(max_n=3,mode='chars',debug=False)\n",
    "#zh_valid_grams = FreedomTokenizer(max_n=3,mode='grams',debug=False)\n",
    "\n",
    "with open(join(path, 'clue/new2016zh/news2016zh_valid.txt'),errors='ignore') as f:\n",
    "    cnt = 0\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        cnt += 1\n",
    "        if (cnt % 1000) == 0:\n",
    "            print(cnt)\n",
    "        zh_valid_chars.train([line])\n",
    "        #zh_valid_grams.train([line])\n",
    "\n",
    "zh_valid_chars.store('data/models/zh_valid_chars_3a')\n",
    "#zh_valid_grams.store('data/models/zh_valid_grams_3a')\n",
    "\n",
    "print(zh_valid_chars.count_params())\n",
    "# 143,129,564\n",
    "\n",
    "#print(zh_valid_grams.count_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47e58af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "del zh_valid_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278319b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bce681c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n"
     ]
    }
   ],
   "source": [
    "zh_train_chars = FreedomTokenizer(max_n=2,mode='chars',debug=False)\n",
    "\n",
    "with open(join(path, 'clue/new2016zh/news2016zh_train.txt'),errors='ignore') as f:\n",
    "    cnt = 0\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        cnt += 1\n",
    "        if (cnt % 100000) == 0:\n",
    "            print(cnt)\n",
    "        zh_train_chars.train([line])\n",
    "        #zh_valid_grams.train([line])\n",
    "\n",
    "zh_train_chars.store('data/models/zh_train_chars_2a')\n",
    "\n",
    "print(zh_train_chars.count_params())\n",
    "# runs out of memory at 45G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f441d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del zh_train_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aabd234d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b4aeb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
