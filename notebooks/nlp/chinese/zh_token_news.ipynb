{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b9861ff",
   "metadata": {},
   "source": [
    "# Chinese (Simplified) Tokenization Model - Experiments - TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfa4a19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "cwd = os.getcwd()\n",
    "project_path = cwd[:cwd.find('pygents')+7]\n",
    "if project_path not in sys.path: sys.path.append(project_path)\n",
    "os.chdir(project_path) \n",
    "\n",
    "from importlib import reload  # Python 3.4+\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "#force reimport\n",
    "if 'pygents.util' in sys.modules:\n",
    "    del sys.modules['pygents.util']\n",
    "if 'pygents.text' in sys.modules:\n",
    "    del sys.modules['pygents.text']\n",
    "if 'pygents.plot' in sys.modules:\n",
    "    del sys.modules['pygents.plot']\n",
    "if 'pygents.token' in sys.modules:\n",
    "    del sys.modules['pygents.token']\n",
    "\n",
    "from pygents.util import * \n",
    "from pygents.text import * \n",
    "from pygents.plot import * \n",
    "from pygents.token import * \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a886e80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.vengaglobal.com/blog/simplified-traditional-chinese-mandarin-cantonese/\n",
    "\n",
    "# Target Market  Written      Spoken\n",
    "# -------------------------------------\n",
    "# China          Simplified   Mandarin\n",
    "# Singapore      Simplified   Mandarin\n",
    "# Taiwan         Traditional  Mandarin\n",
    "# Hong Kong      Traditional  Cantonese\n",
    "\n",
    "# Lexicon:\n",
    "# http://www.chineselexicaldatabase.com/download.php - used below\n",
    "# Sun, C. C., Hendrix, P., Ma, J.Q. & Baayen, R. H. (2018). Chinese Lexical Database (CLD): A large-scale lexical database for simplified Mandarin Chinese. Behavior Research Methods, https://doi.org/10.3758/s13428-018-1038-3.\n",
    "\n",
    "# Corpora:\n",
    "# https://www.openslr.org/38/ - test-audio corpus, not relevant\n",
    "# https://github.com/CLUEbenchmark/CLUECorpus2020/ - email request sent\n",
    "# https://github.com/brightmart/nlp_chinese_corpus - nearly same as above downloaded, used further\n",
    "\n",
    "# TODO:\n",
    "# https://metatext.io/datasets/nlp-chinese-corpus - paper with word segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0942142",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../nlp/corpora/Chinese/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "523eaa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zh_clue_json2text(path,filename):\n",
    "    with open(os.path.join(path,filename+'.json')) as file:\n",
    "        with open(os.path.join(path,filename+'.txt'), 'w') as fout:\n",
    "            while True:\n",
    "                line = file.readline()\n",
    "                if not line:\n",
    "                    break\n",
    "                j = json.loads(line)\n",
    "                #print('title',j['title'])\n",
    "                #print('desc',j['desc'])\n",
    "                #print('content',j['content'])\n",
    "                fout.write(j['title'])\n",
    "                fout.write('\\n')    \n",
    "                fout.write(j['desc'])\n",
    "                fout.write('\\n')    \n",
    "                fout.write(j['content'])\n",
    "                fout.write('\\n')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dd8f704",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do this once!\n",
    "#zh_clue_json2text(path,'clue/new2016zh/news2016zh_valid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5a4778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do this once!\n",
    "#zh_clue_json2text(path,'clue/new2016zh/news2016zh_train')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2989ca52",
   "metadata": {},
   "source": [
    "## Load and explore full models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c22921a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "116000\n",
      "117000\n",
      "118000\n",
      "119000\n",
      "120000\n",
      "121000\n",
      "122000\n",
      "123000\n",
      "124000\n",
      "125000\n",
      "126000\n",
      "127000\n",
      "128000\n",
      "129000\n",
      "130000\n",
      "131000\n",
      "132000\n",
      "133000\n",
      "134000\n",
      "135000\n",
      "136000\n",
      "137000\n",
      "138000\n",
      "139000\n",
      "140000\n",
      "141000\n",
      "142000\n",
      "143000\n",
      "144000\n",
      "145000\n",
      "146000\n",
      "147000\n",
      "148000\n",
      "149000\n",
      "150000\n",
      "151000\n",
      "152000\n",
      "153000\n",
      "154000\n",
      "155000\n",
      "156000\n",
      "157000\n",
      "158000\n",
      "159000\n",
      "160000\n",
      "161000\n",
      "162000\n",
      "163000\n",
      "164000\n",
      "165000\n",
      "166000\n",
      "167000\n",
      "168000\n",
      "169000\n",
      "170000\n",
      "171000\n",
      "172000\n",
      "173000\n",
      "174000\n",
      "175000\n",
      "176000\n",
      "177000\n",
      "178000\n",
      "179000\n",
      "180000\n",
      "181000\n",
      "182000\n",
      "183000\n",
      "184000\n",
      "185000\n",
      "186000\n",
      "187000\n",
      "188000\n",
      "189000\n",
      "190000\n",
      "191000\n",
      "192000\n",
      "193000\n",
      "194000\n",
      "195000\n",
      "196000\n",
      "197000\n",
      "198000\n",
      "199000\n",
      "200000\n",
      "201000\n",
      "202000\n",
      "203000\n",
      "204000\n",
      "205000\n",
      "206000\n",
      "207000\n",
      "208000\n",
      "209000\n",
      "210000\n",
      "211000\n",
      "212000\n",
      "213000\n",
      "214000\n",
      "215000\n",
      "216000\n",
      "217000\n",
      "218000\n",
      "219000\n",
      "220000\n",
      "221000\n",
      "222000\n",
      "223000\n",
      "224000\n",
      "225000\n",
      "226000\n",
      "227000\n",
      "228000\n",
      "229000\n",
      "230000\n",
      "143129564\n"
     ]
    }
   ],
   "source": [
    "zh_valid_chars = FreedomTokenizer(max_n=3,mode='chars',debug=False)\n",
    "#zh_valid_grams = FreedomTokenizer(max_n=3,mode='grams',debug=False)\n",
    "\n",
    "with open(join(path, 'clue/new2016zh/news2016zh_valid.txt'),errors='ignore') as f:\n",
    "    cnt = 0\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        cnt += 1\n",
    "        if (cnt % 1000) == 0:\n",
    "            print(cnt)\n",
    "        zh_valid_chars.train([line])\n",
    "        #zh_valid_grams.train([line])\n",
    "\n",
    "zh_valid_chars.store('data/models/zh_valid_chars_3a')\n",
    "#zh_valid_grams.store('data/models/zh_valid_grams_3a')\n",
    "\n",
    "print(zh_valid_chars.count_params())\n",
    "# 143,129,564\n",
    "\n",
    "#print(zh_valid_grams.count_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47e58af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "del zh_valid_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e30553",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bce681c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n"
     ]
    }
   ],
   "source": [
    "zh_train_chars = FreedomTokenizer(max_n=3,mode='chars',debug=False)\n",
    "\n",
    "with open(join(path, 'clue/new2016zh/news2016zh_train.txt'),errors='ignore') as f:\n",
    "    cnt = 0\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        cnt += 1\n",
    "        if (cnt % 100000) == 0:\n",
    "            print(cnt)\n",
    "        zh_train_chars.train([line])\n",
    "        #zh_valid_grams.train([line])\n",
    "\n",
    "zh_train_chars.store('data/models/zh_train_chars_3a')\n",
    "\n",
    "print(zh_train_chars.count_params())\n",
    "# ???\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c1dbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del zh_train_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f9a8fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b4aeb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
