{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec52562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "cwd = os.getcwd()\n",
    "project_path = cwd[:cwd.find('pygents')+7]\n",
    "if project_path not in sys.path: sys.path.append(project_path)\n",
    "os.chdir(project_path) \n",
    "\n",
    "#from importlib import reload  # Python 3.4+\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "#force reimport\n",
    "if 'pygents.util' in sys.modules:\n",
    "    del sys.modules['pygents.util']\n",
    "if 'pygents.text' in sys.modules:\n",
    "    del sys.modules['pygents.text']\n",
    "if 'pygents.plot' in sys.modules:\n",
    "    del sys.modules['pygents.plot']\n",
    "if 'pygents.token' in sys.modules:\n",
    "    del sys.modules['pygents.token']\n",
    "if 'pygents.token_plot' in sys.modules:\n",
    "    del sys.modules['pygents.token_plot']\n",
    "\n",
    "\n",
    "from pygents.token import *\n",
    "from pygents.text import *\n",
    "from pygents.util import *\n",
    "from pygents.plot import plot_bars, plot_dict, matrix_plot\n",
    "from pygents.token_plot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbd79e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>然后医疗保险呢？就是我们家，不论是大人啊还是小孩都会去买一个保险</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>当他们买了保险的，按照保险合同的话，是要赔三十万的</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>需要意识到买了一个保险的重要性</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>其实这种现象是真的很普遍，因为比如说你买一个人身意外险你那个你买的越多你那个保额就越多</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>这代父母真的很有必要去买一个保险</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>蚂蚁保险不止有车险，我看到上面也有各种。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>但是买房子呢，除了一笔首款付下去之后，每个月的贷款相当于租金</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>这种的投资性的理财，对于个人的财产来说，是具有一定风险</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>如果说你的投资方向正确，那么它是远比存款这一方面要具有更大的优势</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>多一份保险就是多一份保障</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             zh\n",
       "0              然后医疗保险呢？就是我们家，不论是大人啊还是小孩都会去买一个保险\n",
       "1                     当他们买了保险的，按照保险合同的话，是要赔三十万的\n",
       "2                               需要意识到买了一个保险的重要性\n",
       "3   其实这种现象是真的很普遍，因为比如说你买一个人身意外险你那个你买的越多你那个保额就越多\n",
       "4                              这代父母真的很有必要去买一个保险\n",
       "..                                          ...\n",
       "95                         蚂蚁保险不止有车险，我看到上面也有各种。\n",
       "96               但是买房子呢，除了一笔首款付下去之后，每个月的贷款相当于租金\n",
       "97                  这种的投资性的理财，对于个人的财产来说，是具有一定风险\n",
       "98             如果说你的投资方向正确，那么它是远比存款这一方面要具有更大的优势\n",
       "99                                 多一份保险就是多一份保障\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../../nlp/corpora/Chinese/'\n",
    "test_df = pd.read_csv(os.path.join(path,'magicdata/zh_en_ru_100/CORPUS_ZH_EN_RU.txt'),delimiter='\\t')\n",
    "test_texts = list(test_df['zh'])\n",
    "print(len(test_texts))\n",
    "test_df[['zh']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b02d53f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "然后医疗保险呢？就是我们家，不论是大人啊还是小孩都会去买一个保险\n",
      "当他们买了保险的，按照保险合同的话，是要赔三十万的\n",
      "需要意识到买了一个保险的重要性\n",
      "其实这种现象是真的很普遍，因为比如说你买一个人身意外险你那个你买的越多你那个保额就越多\n",
      "这代父母真的很有必要去买一个保险\n",
      "嗯，对现在就是说很提倡买保险\n",
      "车一定要全款买，房子可以贷款买\n",
      "可以去买保险，保险当然分为很多类\n",
      "医疗保险还是很重要的\n",
      "就是保险公司来出这一部分钱\n",
      "相互宝，我不知道你有没有了解过，它是支付宝里面的一种保险\n",
      "买房子其实也就是一个投资\n",
      "你有没有去了解过平安保险公司的培训啊\n",
      "如果要是存银行的话，利息利滚利是多少\n",
      "这个保险在西方国家已经很成熟了\n",
      "保险行业很多啊，你看它覆盖的面积特别广\n",
      "但是，其实也是在鼓励你买商业保险和人寿保险\n",
      "卖保险的都是靠的人脉\n",
      "呃，你买的社保也是保险呀，然后你的车险也是保险呀\n",
      "但是银行的钱，你如果是拿出来的话，属于是一种贷款\n",
      "现在好像转向那个负利率\n",
      "借银行的钱，我真的没试过\n",
      "他是没有利息的，所以他就把它放出去，以后再收回来\n",
      "如果是你征信不好的话，他也不会给钱你用\n",
      "是他是贷款买的还是全款\n",
      "嗯，他们就是就是有时候办一张银行卡的时候，程序特别多\n",
      "各种银行，还有五大银行\n",
      "国债券也算是证券的一种吗\n",
      "其实做股票的话嗯相它是算是风险系数比较高的\n",
      "嗯收益不会太高就跟银行利率是差不多的\n",
      "然后就用来炒房用啊，等它升值了之后卖一套房，然后还清贷款，可能自己还赚了那个几十万\n",
      "入投资入门的话，第一步就是说你要掌握基础知识\n",
      "汇率的标价方式还有他的直接标价法和间接标价法\n",
      "它始终是一种投资的行为，投资的模式，投资的方式\n",
      "如果有闲钱呢买一套公寓来投资呢？\n",
      "变成资金，投资其他的方面\n",
      "有了贷款就有了压力，也就有了挣钱的动力，这个我也认同\n",
      "方不方便开通网上银行啊\n",
      "那你上次投资的钱从哪来的\n",
      "银行的政策的改变让他们不能贷款了\n",
      "保险公司呢它也有理财产品的\n",
      "好像我们那个保险公司是两点八的利息保底\n",
      "所以很多人对保险很反感\n",
      "他们宁愿把那个钱去存银行吃利息\n",
      "提前五年理财真好，因为理财本身就是一个很轻松的事情\n",
      "就是你把你的生活费支出的一小部分作一个储蓄\n",
      "债券基金里这种基金的话，它是收益是比较稳定的，就跟存定期一样，但是比定期的钱要多\n",
      "它理论上可以开多少张这种承兑汇票\n",
      "就是说我们每个人都应该有自己的理财方式，不管你是你理什么财不管你有多少钱\n",
      "是啊，这个贷款再怎么说也要十年以上才能还清\n",
      "投资创业是种非常很大风险的事情\n",
      "等它升值的话，其实也是不错的考虑方向，也是一种投资手段吧\n",
      "其实吧，他们的理财也是很值得我学习的\n",
      "如果说理财是我们生活中必不可少的部分的话\n",
      "比如说我以前就接触过很多什么理财的软件啊\n",
      "它只是帮你把钱保管好可能，但是更多的投资是出于自己\n",
      "我相信的话一个好的理财的话是，嗯能改变自己生活质量的\n",
      "要买要买车买房啊，或者买一些其他东西，然后涉及到钱资金不够，然后肯定也要找银行贷款对吧\n",
      "它也不是说问题不大，就完全没有问题影响的，因为你自己信用信用额度，它不是根据你开了多少张信用卡\n",
      "比如说证券从业资格证，银行从业资格证\n",
      "其实买保险呢，我觉得也是有好处的，你平时就当做是存钱嘛\n",
      "怎么样的才算理赔，什么样才不算理赔\n",
      "确定规划，然后选择合适的商业保险\n",
      "税呀之类的大概五十万，首付五十万，然后要还二十年的贷款\n",
      "而且保险这个覆盖面很全的\n",
      "上到八十岁，下到八岁都可以投保\n",
      "保险就是越来越正规，越来越规范\n",
      "所以说呢，现在还是买保险的这个普及率啊，基本上已经达到了百分之八十以上\n",
      "因为在我们国家来说，保险起步的相对于西方国家来说确实比较晚\n",
      "他那个直接绑定那个银行卡的，信用卡或者是储蓄卡都可以\n",
      "就是在你投保的时候，你自己是不能有这些传染病的嘛\n",
      "现在就是报销的比例提高了以后，加上这个商业保险，作为一个补互补\n",
      "利息高达百分之一百五十以上的那种\n",
      "从法律角度来看呢？保险又是一种合同行为\n",
      "慢慢接触以后我才发现，确实有必要就是入一份保险的，对于自己的孩子了什么的都是有一份保障\n",
      "生育保险和基本医疗保险合并了\n",
      "搭配保险是捆绑销售，其实可以自由搭配\n",
      "但是由于人的生命和身体价值难以估计，所以人身保险并不适用该原则\n",
      "保险事故发生被保险人所得的赔偿金，是由保险公司和被保险人共同分担\n",
      "建立保险制度的目的就是为了对付特定危险事故的发生\n",
      "不在可保范围内，因此商业保险机构一般不承担此类保险\n",
      "比如说你出交通事故，你撞到人了，然后需要赔付一定的金额\n",
      "比如说很简单的一个例子，比如说发生了地震，火灾你觉得保险公司会给你赔付吗\n",
      "具有盈利性商业保险是一种商业行为\n",
      "从法律意义上来说，保险是一种合同行为\n",
      "就是通过签订保险合同，明确双方当事人的权利与义务\n",
      "被保险人以缴纳保费以获取保险合同规定范围内的赔偿\n",
      "保险公司不会给你赔付任何的金额\n",
      "社会保险就是强制要交的五险一金\n",
      "通过银行的基准利率的一个调整呢\n",
      "嗯，发放贷款像给一些企业啊，房地产商啊\n",
      "消费分期拯救了苹果百分之三十的市场份额\n",
      "嗯一年的话，保费的话交多少钱呢\n",
      "你家的车买的什么的保险\n",
      "但是保险公司会理赔呀\n",
      "蚂蚁保险不止有车险，我看到上面也有各种。\n",
      "但是买房子呢，除了一笔首款付下去之后，每个月的贷款相当于租金\n",
      "这种的投资性的理财，对于个人的财产来说，是具有一定风险\n",
      "如果说你的投资方向正确，那么它是远比存款这一方面要具有更大的优势\n",
      "多一份保险就是多一份保障\n"
     ]
    }
   ],
   "source": [
    "for text in test_texts:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65519d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48644\n",
      "1048575\n",
      "99121\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/fxsjy/jieba\n",
    "zh_jieba_tokenizer = JiebaTokenizer()\n",
    "\n",
    "# http://www.chineselexicaldatabase.com/download.php - used below\n",
    "zh_lex_tokenizer = LexiconIndexedTokenizer(lexicon = list(pd.read_csv(os.path.join(path,'lexicon/chineselexicaldatabase2.1.txt'))['Word']))\n",
    "print(zh_lex_tokenizer.count_params())\n",
    "\n",
    "# https://www.plecoforums.com/threads/word-frequency-list-based-on-a-15-billion-character-corpus-bcc-blcu-chinese-corpus.5859/\n",
    "bcc_lex = list(pd.read_csv(os.path.join(path,'lexicon/bcc_global_wordfreq.release_UTF-8.txt'),sep='\\t').to_records(index=False))\n",
    "zh_bcc0_tokenizer = LexiconIndexedTokenizer(lexicon=bcc_lex,sortmode=0)\n",
    "zh_bcc1_tokenizer = LexiconIndexedTokenizer(lexicon=bcc_lex,sortmode=1)\n",
    "zh_bcc2_tokenizer = LexiconIndexedTokenizer(lexicon=bcc_lex,sortmode=2)\n",
    "print(zh_bcc0_tokenizer.count_params())\n",
    "\n",
    "# http://crr.ugent.be/programs-data/subtitle-frequencies/subtlex-ch\n",
    "sub_lex = list(pd.read_csv(os.path.join(path,'lexicon/SUBTLEX-CH-WF.txt'),sep='\\t')[['Word','WCount']].to_records(index=False))\n",
    "zh_sub0_tokenizer = LexiconIndexedTokenizer(lexicon=sub_lex,sortmode=0)\n",
    "zh_sub1_tokenizer = LexiconIndexedTokenizer(lexicon=sub_lex,sortmode=1)\n",
    "zh_sub2_tokenizer = LexiconIndexedTokenizer(lexicon=sub_lex,sortmode=2)\n",
    "print(zh_sub0_tokenizer.count_params())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "204cd1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82\n",
      "0.79\n",
      "0.48\n",
      "0.79\n",
      "0.82\n",
      "0.49\n",
      "0.78\n"
     ]
    }
   ],
   "source": [
    "#http://www.chineselexicaldatabase.com/download.php\n",
    "print(evaluate_tokenizer_f1(test_texts,zh_jieba_tokenizer,zh_lex_tokenizer,debug=False))\n",
    "#ttps://www.plecoforums.com/threads/word-frequency-list-based-on-a-15-billion-character-corpus-bcc-blcu-chinese-corpus.5859/\n",
    "print(evaluate_tokenizer_f1(test_texts,zh_jieba_tokenizer,zh_bcc0_tokenizer,debug=False))#sort by len\n",
    "print(evaluate_tokenizer_f1(test_texts,zh_jieba_tokenizer,zh_bcc1_tokenizer,debug=False))#sort by freq\n",
    "print(evaluate_tokenizer_f1(test_texts,zh_jieba_tokenizer,zh_bcc2_tokenizer,debug=False))#sort by len and freq\n",
    "print(evaluate_tokenizer_f1(test_texts,zh_jieba_tokenizer,zh_sub0_tokenizer,debug=False))#sort by len\n",
    "print(evaluate_tokenizer_f1(test_texts,zh_jieba_tokenizer,zh_sub1_tokenizer,debug=False))#sort by freq\n",
    "print(evaluate_tokenizer_f1(test_texts,zh_jieba_tokenizer,zh_sub2_tokenizer,debug=False))#sort by len and freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fda4953b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1048575\n",
      "1e-06 141441\n",
      "0.79\n",
      "0.48\n",
      "0.79\n",
      "\n",
      "1e-05 52857\n",
      "0.79\n",
      "0.48\n",
      "0.79\n",
      "\n",
      "0.0001 13983\n",
      "0.76\n",
      "0.48\n",
      "0.76\n",
      "\n",
      "0.001 2499\n",
      "0.66\n",
      "0.47\n",
      "0.66\n",
      "\n",
      "0.01 185\n",
      "0.5\n",
      "0.44\n",
      "0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(bcc_lex))\n",
    "filter_thresholds = [0.000001,0.00001,0.0001,0.001,0.01]\n",
    "for t in filter_thresholds:\n",
    "    lex = listofpairs_compress_with_loss(bcc_lex,t)\n",
    "    print(t,len(lex))\n",
    "    zh_bcc0_tokenizer = LexiconIndexedTokenizer(lexicon=lex,sortmode=0)\n",
    "    zh_bcc1_tokenizer = LexiconIndexedTokenizer(lexicon=lex,sortmode=1)\n",
    "    zh_bcc2_tokenizer = LexiconIndexedTokenizer(lexicon=lex,sortmode=2)\n",
    "    print(evaluate_tokenizer_f1(test_texts,zh_jieba_tokenizer,zh_bcc0_tokenizer,debug=False))#sort by len\n",
    "    print(evaluate_tokenizer_f1(test_texts,zh_jieba_tokenizer,zh_bcc1_tokenizer,debug=False))#sort by freq\n",
    "    print(evaluate_tokenizer_f1(test_texts,zh_jieba_tokenizer,zh_bcc2_tokenizer,debug=False))#sort by len and freq\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50f2f953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99121\n",
      "1e-06 69005\n",
      "0.83\n",
      "0.49\n",
      "0.78\n",
      "\n",
      "1e-05 29174\n",
      "0.82\n",
      "0.49\n",
      "0.77\n",
      "\n",
      "0.0001 8343\n",
      "0.74\n",
      "0.49\n",
      "0.72\n",
      "\n",
      "0.001 1621\n",
      "0.63\n",
      "0.49\n",
      "0.63\n",
      "\n",
      "0.01 233\n",
      "0.55\n",
      "0.46\n",
      "0.55\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(sub_lex))\n",
    "filter_thresholds = [0.000001,0.00001,0.0001,0.001,0.01]\n",
    "for t in filter_thresholds:\n",
    "    lex = listofpairs_compress_with_loss(sub_lex,t)\n",
    "    print(t,len(lex))\n",
    "    zh_sub0_tokenizer = LexiconIndexedTokenizer(lexicon=lex,sortmode=0)\n",
    "    zh_sub1_tokenizer = LexiconIndexedTokenizer(lexicon=lex,sortmode=1)\n",
    "    zh_sub2_tokenizer = LexiconIndexedTokenizer(lexicon=lex,sortmode=2)\n",
    "    print(evaluate_tokenizer_f1(test_texts,zh_jieba_tokenizer,zh_sub0_tokenizer,debug=False))#sort by len\n",
    "    print(evaluate_tokenizer_f1(test_texts,zh_jieba_tokenizer,zh_sub1_tokenizer,debug=False))#sort by freq\n",
    "    print(evaluate_tokenizer_f1(test_texts,zh_jieba_tokenizer,zh_sub2_tokenizer,debug=False))#sort by len and freq\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c76cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b76847f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22c1a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e5ef0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289754b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
