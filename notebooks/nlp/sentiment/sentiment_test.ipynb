{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "541bdfcb",
   "metadata": {},
   "source": [
    "# Testing Aigents Sentiment Analysis Web API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77fc69b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pygents.aigents_api.AigentsSentiment at 0x132c61e50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys, math\n",
    "cwd = os.getcwd()\n",
    "project_path = cwd[:cwd.find('pygents')+7]\n",
    "if project_path not in sys.path: sys.path.append(project_path)\n",
    "os.chdir(project_path) \n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "if 'pygents.aigents_api' in sys.modules:\n",
    "    del sys.modules['pygents.aigents_api']\n",
    "if 'pygents.util' in sys.modules:\n",
    "    del sys.modules['pygents.util']\n",
    "\n",
    "from pygents.aigents_api import AigentsSentiment, PygentsSentiment\n",
    "from pygents.util import vector_proximity\n",
    "\n",
    "a = AigentsSentiment(api_url='https://aigents.com/al',debug=True)\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebae767b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pygents.aigents_api.PygentsSentiment at 0x13347ef50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = PygentsSentiment('./data/dict/en/positive.txt',\n",
    "                     './data/dict/en/negative.txt',debug=True)\n",
    "p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a9a2ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('beaming',), ('unbeatable',), ('grovelling',), ('ideally',), ('growing',), ('bodacious',), ('godsend',), ('paramount',), ('productively',), ('captivating',), ('expansion',), ('last', 'word'), ('ennoble',), ('clear-eyed',), ('cultivated',), ('gratifyingly',), ('ruddiness',), ('offer',), ('wowed',), ('livable',)] [('unsupportable',), ('concession',), ('hobbler',), ('superficially',), ('undefined',), ('dyssynergia',), ('narrower',), ('meralgia',), ('surveil',), ('ptsd',), ('undivided',), ('apologists',), ('listless',), ('smelt',), ('flaunt',), ('flax', 'rust', 'fungus'), ('nirvana',), ('sulfurous',), ('confusions',), ('guilty',)]\n"
     ]
    }
   ],
   "source": [
    "print(list(p.positives)[:20],list(p.negatives)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb8e0fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "text: good news\n",
      "json: [{\"negative\":\"0\",\"negatives\":[],\"positive\":\"85\",\"positives\":[\"good\"],\"sentiment\":\"85\",\"text\":\"good news\"}]\n",
      "(0.85, 0.85, -0.0, 0.0, 2, 1) (0.85, 0.85, -0.0, 0.0, 2, 1)\n",
      "--------\n",
      "text: bad news\n",
      "json: [{\"negative\":\"85\",\"negatives\":[\"bad\"],\"positive\":\"0\",\"positives\":[],\"sentiment\":\"-85\",\"text\":\"bad news\"}]\n",
      "(-0.85, 0.0, -0.85, 0.0, 2, 1) (-0.85, 0.0, -0.85, 0.0, 2, 1)\n",
      "--------\n",
      "text: good bad news\n",
      "json: [{\"negative\":\"77\",\"negatives\":[\"bad\"],\"positive\":\"77\",\"positives\":[\"good\"],\"sentiment\":\"0\",\"text\":\"good bad news\"}]\n",
      "(0.0, 0.77, -0.77, 0.77, 3, 1) (0.0, 0.77, -0.77, 0.77, 3, 1)\n",
      "--------\n",
      "text: good and pleasant news about bad things\n",
      "json: [{\"negative\":\"59\",\"negatives\":[\"bad\"],\"positive\":\"74\",\"positives\":[\"good\",\"pleasant\"],\"sentiment\":\"14\",\"text\":\"good and pleasant news about bad things\"}]\n",
      "(0.14, 0.74, -0.59, 0.66, 7, 1) (0.14, 0.74, -0.59, 0.66, 7, 1)\n",
      "--------\n",
      "text: empty spaces\n",
      "json: [{\"negative\":\"0\",\"negatives\":[],\"positive\":\"0\",\"positives\":[],\"sentiment\":\"0\",\"text\":\"empty spaces\"}]\n",
      "(0.0, 0.0, -0.0, 0.0, 2, 1) (0.0, 0.0, -0.0, 0.0, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "texts = ['good news','bad news','good bad news','good and pleasant news about bad things','empty spaces']\n",
    "for t in texts:\n",
    "    s1 = a.get_sentiment(t)\n",
    "    s2 = p.get_sentiment(t)\n",
    "    assert s1 == s2\n",
    "    print(s1,s2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a03a3e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.85, 0.85, -0.0, 0.0, 2, 1)\n",
      "(-0.85, 0.0, -0.85, 0.0, 2, 1)\n",
      "(0.0, 0.77, -0.77, 0.77, 3, 1)\n",
      "(0.14, 0.74, -0.59, 0.66, 7, 1)\n",
      "(0.0, 0.0, -0.0, 0.0, 2, 1)\n",
      "(0.85, 0.85, -0.0, 0.0, 2, 1)\n",
      "(-0.85, 0.0, -0.85, 0.0, 2, 1)\n",
      "(0.0, 0.77, -0.77, 0.77, 3, 1)\n",
      "(0.14, 0.74, -0.59, 0.66, 7, 1)\n",
      "(0.0, 0.0, -0.0, 0.0, 2, 1)\n",
      "(0.85, 0.85, -0.0, 0.0, 2, 1)\n",
      "(-0.85, 0.0, -0.85, 0.0, 2, 1)\n",
      "(0.0, 0.77, -0.77, 0.77, 3, 1)\n",
      "(0.14, 0.74, -0.59, 0.66, 7, 1)\n",
      "(0.0, 0.0, -0.0, 0.0, 2, 1)\n",
      "(0.85, 0.85, -0.0, 0.0, 2, 1)\n",
      "(-0.85, 0.0, -0.85, 0.0, 2, 1)\n",
      "(0.0, 0.77, -0.77, 0.77, 3, 1)\n",
      "(0.14, 0.74, -0.59, 0.66, 7, 1)\n",
      "(0.0, 0.0, -0.0, 0.0, 2, 1)\n",
      "(0.85, 0.85, -0.0, 0.0, 2, 1)\n",
      "(-0.85, 0.0, -0.85, 0.0, 2, 1)\n",
      "(0.0, 0.77, -0.77, 0.77, 3, 1)\n",
      "(0.14, 0.74, -0.59, 0.66, 7, 1)\n",
      "(0.0, 0.0, -0.0, 0.0, 2, 1)\n",
      "(0.85, 0.85, -0.0, 0.0, 2, 1)\n",
      "(-0.85, 0.0, -0.85, 0.0, 2, 1)\n",
      "(0.0, 0.77, -0.77, 0.77, 3, 1)\n",
      "(0.14, 0.74, -0.59, 0.66, 7, 1)\n",
      "(0.0, 0.0, -0.0, 0.0, 2, 1)\n",
      "(0.85, 0.85, -0.0, 0.0, 2, 1)\n",
      "(-0.85, 0.0, -0.85, 0.0, 2, 1)\n",
      "(0.0, 0.77, -0.77, 0.77, 3, 1)\n",
      "(0.14, 0.74, -0.59, 0.66, 7, 1)\n",
      "(0.0, 0.0, -0.0, 0.0, 2, 1)\n",
      "(0.85, 0.85, -0.0, 0.0, 2, 1)\n",
      "(-0.85, 0.0, -0.85, 0.0, 2, 1)\n",
      "(0.0, 0.77, -0.77, 0.77, 3, 1)\n",
      "(0.14, 0.74, -0.59, 0.66, 7, 1)\n",
      "(0.0, 0.0, -0.0, 0.0, 2, 1)\n",
      "(0.85, 0.85, -0.0, 0.0, 2, 1)\n",
      "(-0.85, 0.0, -0.85, 0.0, 2, 1)\n",
      "(0.0, 0.77, -0.77, 0.77, 3, 1)\n",
      "(0.14, 0.74, -0.59, 0.66, 7, 1)\n",
      "(0.0, 0.0, -0.0, 0.0, 2, 1)\n",
      "(0.85, 0.85, -0.0, 0.0, 2, 1)\n",
      "(-0.85, 0.0, -0.85, 0.0, 2, 1)\n",
      "(0.0, 0.77, -0.77, 0.77, 3, 1)\n",
      "(0.14, 0.74, -0.59, 0.66, 7, 1)\n",
      "(0.0, 0.0, -0.0, 0.0, 2, 1)\n",
      "(0.85, 0.85, -0.0, 0.0, 2, 1)\n",
      "(-0.85, 0.0, -0.85, 0.0, 2, 1)\n",
      "(0.0, 0.77, -0.77, 0.77, 3, 1)\n",
      "(0.14, 0.74, -0.59, 0.66, 7, 1)\n",
      "(0.0, 0.0, -0.0, 0.0, 2, 1)\n",
      "(0.85, 0.85, -0.0, 0.0, 2, 1)\n",
      "(-0.85, 0.0, -0.85, 0.0, 2, 1)\n",
      "(0.0, 0.77, -0.77, 0.77, 3, 1)\n",
      "(0.14, 0.74, -0.59, 0.66, 7, 1)\n",
      "(0.0, 0.0, -0.0, 0.0, 2, 1)\n",
      "(0.85, 0.85, -0.0, 0.0, 2, 1)\n",
      "(-0.85, 0.0, -0.85, 0.0, 2, 1)\n",
      "(0.0, 0.77, -0.77, 0.77, 3, 1)\n",
      "(0.14, 0.74, -0.59, 0.66, 7, 1)\n",
      "(0.0, 0.0, -0.0, 0.0, 2, 1)\n",
      "(0.85, 0.85, -0.0, 0.0, 2, 1)\n",
      "(-0.85, 0.0, -0.85, 0.0, 2, 1)\n",
      "(0.0, 0.77, -0.77, 0.77, 3, 1)\n",
      "(0.14, 0.74, -0.59, 0.66, 7, 1)\n",
      "(0.0, 0.0, -0.0, 0.0, 2, 1)\n",
      "(0.85, 0.85, -0.0, 0.0, 2, 1)\n",
      "(-0.85, 0.0, -0.85, 0.0, 2, 1)\n",
      "(0.0, 0.77, -0.77, 0.77, 3, 1)\n",
      "(0.14, 0.74, -0.59, 0.66, 7, 1)\n",
      "(0.0, 0.0, -0.0, 0.0, 2, 1)\n",
      "(0.85, 0.85, -0.0, 0.0, 2, 1)\n",
      "(-0.85, 0.0, -0.85, 0.0, 2, 1)\n",
      "(0.0, 0.77, -0.77, 0.77, 3, 1)\n",
      "(0.14, 0.74, -0.59, 0.66, 7, 1)\n",
      "(0.0, 0.0, -0.0, 0.0, 2, 1)\n",
      "(0.85, 0.85, -0.0, 0.0, 2, 1)\n",
      "(-0.85, 0.0, -0.85, 0.0, 2, 1)\n",
      "(0.0, 0.77, -0.77, 0.77, 3, 1)\n",
      "(0.14, 0.74, -0.59, 0.66, 7, 1)\n",
      "(0.0, 0.0, -0.0, 0.0, 2, 1)\n",
      "(0.85, 0.85, -0.0, 0.0, 2, 1)\n",
      "(-0.85, 0.0, -0.85, 0.0, 2, 1)\n",
      "(0.0, 0.77, -0.77, 0.77, 3, 1)\n",
      "(0.14, 0.74, -0.59, 0.66, 7, 1)\n",
      "(0.0, 0.0, -0.0, 0.0, 2, 1)\n",
      "(0.85, 0.85, -0.0, 0.0, 2, 1)\n",
      "(-0.85, 0.0, -0.85, 0.0, 2, 1)\n",
      "(0.0, 0.77, -0.77, 0.77, 3, 1)\n",
      "(0.14, 0.74, -0.59, 0.66, 7, 1)\n",
      "(0.0, 0.0, -0.0, 0.0, 2, 1)\n",
      "(0.85, 0.85, -0.0, 0.0, 2, 1)\n",
      "(-0.85, 0.0, -0.85, 0.0, 2, 1)\n",
      "(0.0, 0.77, -0.77, 0.77, 3, 1)\n",
      "(0.14, 0.74, -0.59, 0.66, 7, 1)\n",
      "(0.0, 0.0, -0.0, 0.0, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "a = AigentsSentiment(api_url='https://aigents.com/al',debug=False)\n",
    "t1 = dt.datetime.now()\n",
    "for c in range(20):\n",
    "    for t in texts:\n",
    "        s = a.get_sentiment(t)\n",
    "        print(s)    \n",
    "t2 = dt.datetime.now()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3a35ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=9, microseconds=620092)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2-t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61909987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b913f9bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.31, 0.0, -0.31, 0.0, 31, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.get_sentiment('Technopolis plans to develop in stages an area of no less than 100,000 square meters in order to host companies working in computer technologies and telecommunications , the statement said .')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47b4d02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.54, 0.0, -0.54, 0.0, 39, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.get_sentiment(\"For the last quarter of 2010 , Componenta 's net sales doubled to EUR131m from EUR76m for the same period a year earlier , while it moved to a zero pre-tax profit from a pre-tax loss of EUR7m .\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cbbaa63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0, -0.0, 0.0, 30, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.get_sentiment(\"Clothing retail chain Sepp+Æl+Æ 's sales increased by 8 % to EUR 155.2 mn , and operating profit rose to EUR 31.1 mn from EUR 17.1 mn in 2004 .\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f502e078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pygents.aigents_api.AigentsSentiment at 0x10d300390>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = AigentsSentiment(api_url='https://aigents.com/al',debug=True)\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b42baee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "text: Technopolis plans to develop in stages an area of no less than 100,000 square meters in order to host companies working in computer technologies and telecommunications , the statement said .\n",
      "json: [{\"negative\":\"31\",\"negatives\":[\"square\"],\"positive\":\"0\",\"positives\":[],\"sentiment\":\"-31\",\"text\":\"Technopolis plans to develop in stages an area of no less than 100,000 square meters in order to host companies working in computer technologies and telecommunications , the statement said .\"}]\n",
      "(-0.31, 0.0, -0.31, 0.0, 31, 1)\n",
      "--------\n",
      "text: Technopolis plans to develop in stages an area of no less than 100,000 square meters\n",
      "json: [{\"negative\":\"44\",\"negatives\":[\"square\"],\"positive\":\"0\",\"positives\":[],\"sentiment\":\"-44\",\"text\":\"Technopolis plans to develop in stages an area of no less than 100,000 square meters\"}]\n",
      "(-0.44, 0.0, -0.44, 0.0, 15, 1)\n",
      "--------\n",
      "text: Technopolis plans to develop in stages an area of no less than\n",
      "json: [{\"negative\":\"0\",\"negatives\":[],\"positive\":\"0\",\"positives\":[],\"sentiment\":\"0\",\"text\":\"Technopolis plans to develop in stages an area of no less than\"}]\n",
      "(0.0, 0.0, -0.0, 0.0, 12, 1)\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    'Technopolis plans to develop in stages an area of no less than 100,000 square meters in order to host companies working in computer technologies and telecommunications , the statement said .',\n",
    "    'Technopolis plans to develop in stages an area of no less than 100,000 square meters',\n",
    "    'Technopolis plans to develop in stages an area of no less than'\n",
    "]\n",
    "for t in texts:\n",
    "    s = a.get_sentiment(t)\n",
    "    print(s)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c44e53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac8a4dd4",
   "metadata": {},
   "source": [
    "## Test Configurable Sentiment Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b7b5948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good news (0.85, 0.85, -0.0, 0.0, 2, 1)\n",
      "not bad news (0.92, 0.92, -0.0, 0.0, 3, 1)\n",
      "not good news (-0.92, 0.0, -0.92, 0.0, 3, 1)\n",
      "bad news (-0.85, 0.0, -0.85, 0.0, 2, 1)\n",
      "just news (0.0, 0.0, -0.0, 0.0, 2, 1)\n",
      "bad good news (0.0, 0.77, -0.77, 0.77, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "#English - default tokenization (works)\n",
    "\n",
    "en_p = PygentsSentiment({('good',),('not','bad',)},{('not','good'),('bad',)},debug=True)\n",
    "\n",
    "en_texts = ['good news','not bad news','not good news','bad news','just news','bad good news']\n",
    "for t in en_texts:\n",
    "    s1 = en_p.get_sentiment(t)\n",
    "    s2 = p.get_sentiment(t)\n",
    "    assert s1 == s2\n",
    "    print(t,s1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d3fef98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "好 消息 (0.85, 0.85, -0.0, 0.0, 2, 1)\n",
      "不 壞 消息 (0.92, 0.92, -0.0, 0.0, 3, 1)\n",
      "不 好 消息 (-0.92, 0.0, -0.92, 0.0, 3, 1)\n",
      "壞 消息 (-0.85, 0.0, -0.85, 0.0, 2, 1)\n",
      "只是 消息 (0.0, 0.0, -0.0, 0.0, 2, 1)\n",
      "壞 好 消息 (0.0, 0.77, -0.77, 0.77, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "#Chinese - forced tokenization (works)\n",
    "\n",
    "zh_p = PygentsSentiment([('好',),('不','壞',)],{('不','好'),('壞',)},debug=True)\n",
    "\n",
    "zh_texts = ['好 消息','不 壞 消息','不 好 消息','壞 消息','只是 消息','壞 好 消息']\n",
    "for zh_t,en_t in zip(zh_texts,en_texts):\n",
    "    s1 = zh_p.get_sentiment(zh_t)\n",
    "    s2 = p.get_sentiment(en_t)\n",
    "    assert s1 == s2\n",
    "    print(zh_t,s1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1165fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('不', '壞'), ('好',)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zh_p.positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "decdffa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "好消息 (0.0, 0.0, -0.0, 0.0, 1, 1)\n",
      "不壞消息 (0.0, 0.0, -0.0, 0.0, 1, 1)\n",
      "不好消息 (0.0, 0.0, -0.0, 0.0, 1, 1)\n",
      "壞消息 (0.0, 0.0, -0.0, 0.0, 1, 1)\n",
      "只是消息 (0.0, 0.0, -0.0, 0.0, 1, 1)\n",
      "壞好消息 (0.0, 0.0, -0.0, 0.0, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "#Chinese - no tokenization (does not work, needs extra care)\n",
    "\n",
    "zh_p = PygentsSentiment([('好',),('不壞',)],{('不好'),('壞',)},debug=True)\n",
    "\n",
    "zh_texts = ['好消息','不壞消息','不好消息','壞消息','只是消息','壞好消息']\n",
    "for zh_t,en_t in zip(zh_texts,en_texts):\n",
    "    s1 = zh_p.get_sentiment(zh_t)\n",
    "    s2 = p.get_sentiment(en_t)\n",
    "    #assert s1 == s2\n",
    "    print(zh_t,s1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c441fd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "好消息 (0.77, 0.77, -0.0, 0.0, 1, 1)\n",
      "不壞消息 (0.85, 0.85, -0.0, 0.0, 1, 1)\n",
      "不好消息 (-0.85, 0.0, -0.85, 0.0, 1, 1)\n",
      "壞消息 (-0.77, 0.0, -0.77, 0.0, 1, 1)\n",
      "只是消息 (0.0, 0.0, -0.0, 0.0, 1, 1)\n",
      "壞好消息 (0.0, 0.71, -0.71, 0.71, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "#Chinese - char-based tokenization (works)\n",
    "\n",
    "zh_p = PygentsSentiment([('好',),('不壞',)],{('不好'),('壞',)}, tokenize_chars=True, debug=True)\n",
    "\n",
    "zh_texts = ['好消息','不壞消息','不好消息','壞消息','只是消息','壞好消息']\n",
    "for zh_t,en_t in zip(zh_texts,en_texts):\n",
    "    s1 = zh_p.get_sentiment(zh_t)\n",
    "    s2 = p.get_sentiment(en_t)\n",
    "    assert vector_proximity(s1[:4], s2[:4], 0.1) #assert values are close (will be different due to tokenization)\n",
    "    print(zh_t,s1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7110fdbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f91777d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
