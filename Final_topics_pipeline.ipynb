{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/samsonbobo/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file saved as: multi_word_topics.csv\n",
      "Processed file saved as: single_word_topics.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "import re\n",
    "nltk.download('words')\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"final_topics.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Load English words set for filtering meaningful words\n",
    "english_words = set(words.words())\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans text by removing special characters, HTML-like elements, and non-meaningful words.\n",
    "    \"\"\"\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove special characters\n",
    "    text = re.sub(r'\\b[a-zA-Z]{1,2}\\b', '', text)  # Remove single letters and very short words\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    return text.lower()\n",
    "\n",
    "def extract_multi_word_phrases(text_group):\n",
    "    \"\"\"\n",
    "    Extract top 5 unique multi-word phrases (2-4 words) based on frequency, ensuring meaningful phrases.\n",
    "    \"\"\"\n",
    "    all_text = \" \".join(text_group)\n",
    "    all_text = clean_text(all_text)\n",
    "    \n",
    "    potential_phrases = re.findall(r'\\b(?:\\w+\\s+){1,3}\\w+\\b', all_text)  # Extract 2-4 word phrases\n",
    "    \n",
    "    filtered_phrases = [phrase for phrase in potential_phrases \n",
    "                         if all(word in english_words for word in phrase.split())]\n",
    "    \n",
    "    phrase_counts = Counter(filtered_phrases)\n",
    "    threshold = max(phrase_counts.values()) * 0.7 if phrase_counts else 0  # Dynamic threshold\n",
    "    \n",
    "    selected_phrases = [phrase for phrase, count in phrase_counts.items() if count >= threshold]\n",
    "    \n",
    "    return selected_phrases[:5]  # Limit to 5 phrases per category\n",
    "\n",
    "# Extract multi-word phrases per category\n",
    "multi_word_df = df.groupby(\"category\")[\"cleaned_keywords\"].apply(extract_multi_word_phrases).reset_index()\n",
    "multi_word_df[\"selected_multi_word_phrases\"] = multi_word_df[\"cleaned_keywords\"].apply(lambda x: \", \".join(x))\n",
    "\n",
    "# Merge timestamps for multi-word phrases\n",
    "timestamps = df.groupby(\"category\")[\"timestamp\"].first().reset_index()\n",
    "multi_word_df = pd.merge(timestamps, multi_word_df, on=\"category\")[[\"timestamp\", \"category\", \"selected_multi_word_phrases\"]]\n",
    "\n",
    "# Save multi-word topics\n",
    "multi_word_output_path = \"multi_word_topics.csv\"\n",
    "multi_word_df.to_csv(multi_word_output_path, index=False)\n",
    "\n",
    "print(\"Processed file saved as:\", multi_word_output_path)\n",
    "\n",
    "# Function to extract single-word phrases\n",
    "\n",
    "def extract_single_word_phrases(text_group, multi_word_list):\n",
    "    \"\"\"\n",
    "    Extract top 5 unique single-word phrases based on frequency, ensuring they are not in multi-word phrases.\n",
    "    \"\"\"\n",
    "    all_text = \" \".join(text_group)\n",
    "    all_text = clean_text(all_text)\n",
    "    words_list = all_text.split()\n",
    "    \n",
    "    filtered_words = [word for word in words_list if word in english_words and word not in multi_word_list]\n",
    "    \n",
    "    word_counts = Counter(filtered_words)\n",
    "    threshold = max(word_counts.values()) * 0.7 if word_counts else 0  # Dynamic threshold\n",
    "    \n",
    "    selected_words = [word for word, count in word_counts.items() if count >= threshold]\n",
    "    \n",
    "    return selected_words[:5]  # Limit to 5 words per category\n",
    "\n",
    "# Extract single-word phrases per category\n",
    "multi_word_dict = dict(zip(multi_word_df[\"category\"], multi_word_df[\"selected_multi_word_phrases\"].apply(lambda x: x.split(\", \") if isinstance(x, str) else [])))\n",
    "single_word_df = df.groupby(\"category\")[\"cleaned_keywords\"].apply(lambda x: extract_single_word_phrases(x, multi_word_dict.get(x.name, []))).reset_index()\n",
    "single_word_df[\"selected_single_phrases\"] = single_word_df[\"cleaned_keywords\"].apply(lambda x: \", \".join(x))\n",
    "\n",
    "# Merge timestamps for single-word phrases\n",
    "single_word_df = pd.merge(timestamps, single_word_df, on=\"category\")[[\"timestamp\", \"category\", \"selected_single_phrases\"]]\n",
    "\n",
    "# Save single-word topics\n",
    "single_word_output_path = \"single_word_topics.csv\"\n",
    "single_word_df.to_csv(single_word_output_path, index=False)\n",
    "\n",
    "print(\"Processed file saved as:\", single_word_output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of    timestamp       category                        selected_multi_word_phrases\n",
       "0    2024-03       business                            like helping washed pap\n",
       "1    2024-03        climate  embracing change weakness pathway, symbol endu...\n",
       "2    2024-03        economy  going organize earn money, pause mantra employ...\n",
       "3    2024-03      education  layout support community account, constantly i...\n",
       "4    2024-03  entertainment  photography beautiful natural hope, like pray ...\n",
       "5    2024-03        fashion                    essential woman wardrobe choose\n",
       "6    2024-03           food  season begin chef love, great pleasure fine ha...\n",
       "7    2024-03         health  continued greet good spirit, risk neurodegener...\n",
       "8    2024-03         movies                                                NaN\n",
       "9    2024-03          music                            better use dose looking\n",
       "10   2024-03       personal  sublime lose hope god, explore dynamic trust b...\n",
       "11   2024-03       politics                                                NaN\n",
       "12   2024-03  relationships  time thats hardly theyre, child able visiting ...\n",
       "13   2024-03       religion  winning woman prayerful wonderful, trust feel ...\n",
       "14   2024-03        science                                                NaN\n",
       "15   2024-03         sports                           sink sat breakfast start\n",
       "16   2024-03     technology          peace love youve got, love youve got free\n",
       "17   2024-03         travel                                city view blue walk>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/samsonbobo/Desktop/Research Topic/Thesis/multi_word_topics.csv')\n",
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of    timestamp       category                       selected_single_phrases\n",
       "0    2024-03       business       marketing, patience, promotion, project\n",
       "1    2024-03        climate            presence, blossom, colors, support\n",
       "2    2024-03        economy                                      category\n",
       "3    2024-03      education                   support, community, android\n",
       "4    2024-03  entertainment                                        flower\n",
       "5    2024-03        fashion                                       fashion\n",
       "6    2024-03           food                      milk, prepare, breakfast\n",
       "7    2024-03         health       various, time, essential, weak, healthy\n",
       "8    2024-03         movies                                         movie\n",
       "9    2024-03          music                                       premium\n",
       "10   2024-03       personal                                    div, diary\n",
       "11   2024-03       politics           good, cabinet, money, sure, relieve\n",
       "12   2024-03  relationships                  celebrate, enhancer, android\n",
       "13   2024-03       religion           concept, church, ate, health, sense\n",
       "14   2024-03        science  extract, gold, electronic, category, science\n",
       "15   2024-03         sports                                   event, took\n",
       "16   2024-03     technology              android, peace, love, youve, got\n",
       "17   2024-03         travel             traveling, walk, city, view, blue>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('/Users/samsonbobo/Desktop/Research Topic/Thesis/single_word_topics.csv')\n",
    "df1.head"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
